{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bxiG8TZH3H4",
        "outputId": "9ae12a03-b6a7-4328-ab83-bbf6237787f0"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 11.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 31.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 52.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=6b067e60fd2a19e8e66b1aae2460303985c0f2bf20d632fcbba493f466de0b1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763,
          "referenced_widgets": [
            "5fa21790588a480dbaa9483bc99aeeb0",
            "b4c5ba8d385245aba8cb2b9497235f94",
            "7a84b76367e04663bb6bdd2ac3ba83dd",
            "15a6cc004e1f48eaa846b68e275858e7",
            "51eafbde636f46e985af876bcb3ffff6",
            "7b87b7d0cf3743cbbbcbeec4109d8e4e",
            "54e717a6df6749fa973fb5d5794f9c94",
            "d868b22e76894d84b161c717a36f6f91",
            "3a7278a54b584c3dad57901a41cb1f16",
            "5aafeb5d079f4cb495ee6afe08211d1f",
            "a094ea56eac340118edea6fc1ce853c9",
            "9ba2bf3b724a45a7a7672cb1af022170",
            "ab93d7ff8ae24ec8887341d93ab9a834",
            "410f8205fbcc448b8b43c7dd416ab330",
            "367b309fa3234e0db718fea5f2cc2e59",
            "b952bc50f3f74f4c8d2dbfd574ea171b",
            "48970260cbef49d393a9100a6b51a998",
            "d600a00608b84c6b9881099757540083",
            "4841d599adfe46d6b82333ea4fd3c1ba",
            "06748924fb884171b9144c7c54194c01",
            "0b7191c0eea24b9c9b7909b2596a752a",
            "31dfe5e3d15b40c297a8bf58dec0e4d9",
            "24e8fb0fb27f4206a1187b6cc72db355",
            "9660af15c19a4153bbf5ef31f7f2dd8a",
            "8d4f9ecb111e4d55b6e92ce6ceef0339",
            "eb639de036934bf6846e09b7fcce5031",
            "5d960345afeb417c9ea4f627cdbcc2d3",
            "631a46bffed64845adb1bedac1aba00a",
            "8b5b3b76eb654b6d864b9abc5f305d8d",
            "e397343e96e5470191622577047d6982",
            "abc3b21c56ca4138bf5c99fb5e30203e",
            "0bd0055375544b449ae87bae89b439ea",
            "1efef368212a4ce5996f9c2625c21c1e"
          ]
        },
        "id": "cpkdXE7aECfR",
        "outputId": "73d4cd6f-13f7-40b6-9747-aaa1b104dc41"
      },
      "source": [
        "# Manual testing:\n",
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "model = SentenceTransformer('uclanlp/visualbert-nlvr2-coco-pre')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings.shape, embeddings[0, :10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260419496016 on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260419496016 acquired on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fa21790588a480dbaa9483bc99aeeb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260419496016 on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260419496016 released on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260419495952 on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/config.json.lock\n",
            "DEBUG:filelock:Lock 140260419495952 acquired on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ba2bf3b724a45a7a7672cb1af022170",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/631 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260419495952 on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/config.json.lock\n",
            "DEBUG:filelock:Lock 140260419495952 released on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260455922064 on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260455922064 acquired on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24e8fb0fb27f4206a1187b6cc72db355",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260455922064 on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260455922064 released on /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre/pytorch_model.bin.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/uclanlp_visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c6091ff6cf6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"This is an example sentence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Each sentence is converted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uclanlp/visualbert-nlvr2-coco-pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_sbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m#Load with AutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_auto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_auto_model\u001b[0;34m(self, model_name_or_path)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \"\"\"\n\u001b[1;32m    789\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No sentence-transformers model found with name {}. Creating a new one with MEAN pooling.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0mpooling_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_embedding_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_name_or_path\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_name_or_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#No max_seq_length set. Try to infer from model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_class_to_model_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_config_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: <class 'transformers.models.visual_bert.configuration_visual_bert.VisualBertConfig'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "848ed0277d814dab96951d76563d7f8a",
            "7f7ae29d411a452e847097aef30be5e3",
            "4df206f3f6534c6b8da9a704651ce314",
            "fad4c6995b484f01883727bba68bdaa0",
            "8f2d7ea9dd02461ca9a63b40bccff11e",
            "2bb0f70b10354322a349baf57f0acafb",
            "577df779591d4968a21ec6fd05bd19ac",
            "5eee0cf0ea524d068e0a74cc6476f9db",
            "7cde17965afb4435a845f295965abb85",
            "0817acf0640e4375a4df4e352db29728",
            "60dcb56d3c7a4d3a8fa313205923e18c",
            "66742411db834fb089eb598b5cd43fbf",
            "3c5bff7bcdfd4619b37af3d8813a3ab4",
            "a261136008ec467f96dcced431a43b45",
            "260d119891ff4615b546646fd85938a3",
            "c4d46ec3e8584e51ab4786dca50daa18",
            "d70aaac956cb43a8a9bcd2a121e788de",
            "a620ed345fe744ee9d3e1b9eef87e311",
            "191b4abd616c431f9d9b3c65010a4cd3",
            "f583ba184a394a4cabbc5f7aaf0a9756",
            "23643a93c79945569be3fa0358bb76c6",
            "a41396a585304ec08ca5ec1c4d2e577d",
            "1d3eeeec405e489aa7c4a7a669ffd01e",
            "61b250a14501448f9270f53b6feef25a",
            "bfb7429ff5db43a5b24b159c78e5892b",
            "86aa22ec7f884bfbb585e3c909ce99f1",
            "086330b776704665b47dce3b84db70d7",
            "31aebbd6d77f406ca802d688ed4c1d4f",
            "96e4d8294bd9478a81001b9796202bc8",
            "5053c30dfb94479a9f0a78141f4d9a36",
            "da44890c42b74ffd8cfd0a65f93f77c0",
            "806ca18d8d6349668bbe508a414a5711",
            "6f15691c46b44dd9ac03f49042fb8e4f",
            "912150ea3aad48bcaa98444c7fb65fe5",
            "82b54db028f3444fb0e24f43e0087b7d",
            "fc2fdc00d01646599d1fab80a996914d",
            "6ca7a49ad4014e80b297efc8cdf80caf",
            "4930a02621304461847fe0781a16994c",
            "c9c6ec3bdafe4f0c9063b5686ac3bc9a",
            "07cb50c39f1d451688392c860c1e1916",
            "4b9df02aebfc4765b8c07fe260d296de",
            "cee5dee3d5164dbcba3fcfdda4c53fab",
            "962afb155f4e4927b73e322544be9e77",
            "07fcb2438a66498caa53c8a721bdde77",
            "11713912474f4c6dac9445f2b70fd230",
            "f60535eff4ec4e8287ebe64cc44158ab",
            "d7eb116325b347359b3a0f943b66f859",
            "7d54c7f68fef49aeacd8616ad27e89c5",
            "82024cc6142045918dedfea722ac9580",
            "a33579d6cbe34c298f49f7b16557404c",
            "71567e1489ea4e9eb16e9ed7392ce193",
            "e84cf8714cbe40efb4e5e9d0d1ee647b",
            "ad7e5b25c57d4418bba83e164d0b8c81",
            "a5af990192104ddd9bed52b830ce0236",
            "8f24033a510b451698c189ccda182810",
            "1dabd934415d4b098b4d010cde0085f0",
            "5913b39b605643788a0f0bc56eba6b2c",
            "90d8b65850224bd2a0e457171be3f33a",
            "ee90d91f18b2423b97c0e6f832feb8b8",
            "6f1ffcb23e884e66a9d7d5dad90d0634",
            "9f98fc10f2124c5dac91ba3d8a494875",
            "875d0d03c9db4ed98f5bad3faae90347",
            "6058e05098a0451a8b5e30c3a9ac9c8b",
            "244542cfd1274393b8e116d854f360f3",
            "30b9a8dab09a46d18db93d50b4fc1ef5",
            "fcff90067987451fb817ebb371f37b6c",
            "db2e296f0fe540329351b31ce8c4e018",
            "94c864b465cf4cfb93c10dea4aba2698",
            "249270884d9b458f8cda59821e5cccd3",
            "f711e977781a47fb9d983420cf8ebe05",
            "d99a2d705d7544229285a7b0a30c794b",
            "ad60da750e6d4ff8aaaa76e725622fb7",
            "2b5e95181d1a412f98c531523efd8d41",
            "c63906e62d834a9aa99e7d42262f72d2",
            "495ea5c2886b4b2bbe4c80b04c50f48a",
            "9c5b04bf0a86402eb9ffaff7d906e604",
            "becae79bd5644ad59b7490779379c6d7",
            "192908063e91435b87d9d05c4fec07b7",
            "a35c55791e104423a03c4630e3a1c5ce",
            "93b4463ac321421a8e3bbf4c9d3b80dc",
            "d1af4cc6386947349ff0790332fbb161",
            "3e3c3a23a39548b1836fa39d27799cfa",
            "4f167462640041959b34717f70c85d78",
            "2dbbfd5088ee410aaddc37614fe69baa",
            "df147eeecc4249ad81d41d58ad280b44",
            "cf818a6a6cab483bb04275c2b9d61017",
            "77b545fc38334317a024538f68cc1331",
            "86d9e5dd2cdf4a53a19d11cd34fae265",
            "af844f36413d46fab637c23b9b6deb59",
            "664314cb6d8c49b58bada9e9512a8ebc",
            "a5f0bb7c19784584ae198625771f17b9",
            "eecb4145b42749cfa83c177fbb44e5b3",
            "4059e980578d4aa18d4c0b07ee00a245",
            "76bf56ac5abf45688adf0b3c51f7e6a6",
            "fd99c6b43254483085185468eff05fc5",
            "ae2e9ff7cd9d49e7874116bdd12ad432",
            "609abd5e1f2645d98ad429a10a3faea6",
            "e13c78f28f8a4f1fa94ef723170b2dd6",
            "5ae1b7597d604802bbee892a7f7e984d",
            "30a5baf29089421cbc305abc49a1868a",
            "a07c64a45a5a408fa436f19c38f05031",
            "2cce5269f814415bbe8e8a7c2f7b670d",
            "d55fa62d15de49bf812bd994fe096f69",
            "9a0e5042c32340eda54280f8c2bf3116",
            "83c7a88188ad42769f5a7e51cae14339",
            "081e0ca677e747639d282aa86c6989ae",
            "7952803fe21e43028168d51521a5a78d",
            "37f9bb313e2e48c39c51b4118466ccc7",
            "5543b6a7e8eb418f978e08b22b0a14ef",
            "74f5067d39704a719dacda428eecc9cc",
            "4aebe323ebd74be199e6b9a1b0153abd",
            "67ebf42227e145a68c2b74051eb782e0",
            "4bf1f0e7e26b4375accbb588230b653a",
            "41d430a4f5b343fb82bcd8d53102cb96",
            "b139391128a044a1b79d1ee9bf19f47c",
            "193c674d7e2e4cc786c8e37dd8c38cf8",
            "0e9c1bf0ac1d41e8906bbe7982babf42",
            "0411bdf45fb34c34aa29f1e4744521ff",
            "8e18329b913c4ae488cf651756a50632",
            "0385c9a1ac7641bebbebf267d56686ea",
            "01ba545740f948ab91bdbf9d276e924f",
            "5c620abc2940454ba093671820f7c7cd",
            "110045d2cd9748ae83ce149bbc1aa6a8",
            "bf75d182bac64ab0a416560d8e3d8c45",
            "e4b2d66a39ba4b7e9a928034321696a0",
            "f063e51de3c24a38a27c92a9600c1b89",
            "a677532126db42909632c9a8b1a8a8d0",
            "49ace6c1060845aca1c134253d881fd5",
            "4d457df3259840d2a87b264bc9b7f76c",
            "98711a59100944daa9c02134c1f9d0c0",
            "6f6e759867df48f0b547e473f1475a90",
            "89dafed4229842dea662897c5559dcaa",
            "e2783749a68e4ff3bdc5181e37d2ff59",
            "5bc7da438ade4ee0a681a104890ad341",
            "9d755819e3934b06bfe868c8a006d74b",
            "8e3f4540cadd4b239a3db9131052e39d",
            "6e8176f1dc1849e481a17f5baf9c4b94",
            "74c72944cfba48c9a296a1dfd88c0b0b",
            "906bd9ed9844420b82d6ad06bc9e710b",
            "e547a2e461f24a7f890da0617a9d90c8",
            "fdde87392b2d4e9db3ae72fd414ef966",
            "a092ee417a1843109123ba958cb83549",
            "c0d8bf1e534b4ec19d001132d17c696f",
            "1883b82e247d49d29e4b744a0837bf40",
            "0ad0ad79b2314749897619ccc2192bc5",
            "dcd7bf8f977146e0a7e2127c025e2b80",
            "745a1bd76c5240ce86fb2d4e8a9e329a",
            "bfec2cdb895b4658a15ba1c5830d5b5f",
            "446e5c36a3384ca883848f37502ece5a",
            "579a9efef93040e1993e9868bac7c3ff",
            "e3b58ac9dc414b9190a2e391763cc366",
            "c79afaa3862c4546b77aef431dcd5094",
            "770c3546be434ebfb869e92626f9fdd4",
            "518ac8e3b87c4c28ba85f982cce2f304",
            "28dad7df3cea4b9682c943e3d88013f7",
            "39930c9fa65940c48948ad9e726e744b",
            "c06ac96070c5464aa4cefccbe476e42e",
            "67c771ddb905434e9b969701304bd982",
            "e7cd681ef4ba4300896c79c37f116ffe",
            "84047859ac46461d8b7a50bf74a5f99e",
            "ec77005f54a14d1084683891f77ceacb",
            "4a6bda4304cc48fca798a7cbd3d38e7c",
            "47f13e205b9d43f68097ec2b0eb886d1",
            "eaeb27ca8fce42f2831c0728bc7ad220",
            "66d05574f56d4b4c8d7af99748f2f34e",
            "75f8f837cd954be0b6ce2ad6e14993ac",
            "b34a224710c248cb9a26fca14800e714",
            "57fec2a72b8b40c8a91e64c9c8ec47c9",
            "b831ea0deb254d68a60f3533130de14a",
            "0f5c0e992e714a37a36ca8bdeb59e63b",
            "11d7d8282281442f91fa18c8e964d24c",
            "49abdbed0e4c431f9d68bfba28ac9c7c",
            "b5653e8c61cb474d8b757a2d82cfdb12",
            "40c6c02d24964cb6982f51f3716d1935",
            "a20af7a813624a82978c88219ed66857",
            "e8a8d204d789499398241a81a11e1e3d",
            "49d20422564543809ac7bd3068633996",
            "8da455c767024b848325e6dbdeb39db4",
            "dae0f33509714e41a96244c41741afee",
            "bad608f97f354a4392e7391ef49fd9a2",
            "ac19ae2d0d074d05b75842e95edb046e",
            "17a05b5b6b444d55b779a6467051ebaf",
            "beaec0960c3c4d5d8502108d8669f9c3",
            "e511678159604cd29166a2fa4c179214",
            "7ef89f4d67714e47adbed10fa53b274b",
            "dad7cdf7235343b38bdaf8404c2e7072",
            "93e5f9dcb75a4a55b3f636c143ab538b",
            "346c5b6a2b854133be24948b7f3fa1b0",
            "baf14145cc9c4856bf379cb7211dfb7d",
            "5e11ea09af1f479b9cb7353672e77376",
            "7d373c87fd1b4f00b342ecf32858b189",
            "5712fe28bc154f2980c9a06143b923cb",
            "708d3575cb2d47f2ae3c5806e8e51d32",
            "883a200e4c44449284237df02efdcb16",
            "c758d58662264b4cb6eeffb158440904",
            "39f64fbd54cd44d4b2b458a05c7f983c",
            "d3c98b3972d642bb99054e8086f27158",
            "279b5b9fb90b4205bfaa8bb568d66604",
            "e65271f0c57644a19305e841df7be60d",
            "f2e047eeca864e74b19fa24d1e1eb5f3",
            "ce6f50028d194025a561680be87651f1",
            "deb07d9e3a174d9786a7ff87f9895887",
            "dd63145b8683402399b5b4f60b8a69d6",
            "d4fa5d2e94b145b396e0146797eb1e4f",
            "8488e38d2fb14b9aad5b74b8c6d5498e",
            "dd95e0601b044d0d8e9d552e525cd55f",
            "fbaac54947364580a12d698d08e946be",
            "2578842d0044402b917ec9ef09d83e53",
            "73de342d883f48fdac8a7b1e3545cba4",
            "2be000cbe2844e4cbb91ad03fb9f616c",
            "b744cda4bdd64f9cb1d22ce7794ba4e4",
            "164cb2feb9bf4e839149ef2273f31166",
            "51bbfefe12fb43c1991d933bb75862f1",
            "bcc43928365d420cbf39fc66f17b1f11",
            "7b35c95ed4454d92b789ec64450eeb14",
            "718907ce881441a19d0585ba0c782893",
            "3457b3dafd7448a484338070a8feafb0",
            "1305e208fe0e452ba2ab2ae30d9d1394",
            "dce5393c69134109b05d10ed4956376c",
            "0dfc4851d0c9462c8fedaaa779b28944",
            "3443788fc1bc46c0b6203458fb59029e",
            "d29838c09828427a9cc2925e041e8005",
            "ff2db5bd1bf24960b459fb5d63a9113a",
            "5858e74d1ffc4372bfddfd90e6cd29f1",
            "78aa6e2909c647368f9b6db005df6998",
            "1a727b0861074d98ba7224bd3251060a",
            "78e1336163c4447c85a1c8716a3a9a66",
            "8d2827172af7486a9cb14548ef93621b",
            "46a4854b880646e09b1da26681275e89",
            "66ec2e078de14f0c8942d683a31f6f99",
            "b484d7dddf8c45fcbb53f547d0a15ad2",
            "3b95969e9bf2435f8dacec274382bc80",
            "76018f8e54ee4c4f82e9f56f3b63456e",
            "5966401bb8ea4675a11d709f44d210b1",
            "8c61e013c4c84c03a04d778688b60454",
            "0e2d06c759b04c449cd95b0d53025ff0",
            "02c1f39ed0bf4241bedf99d44a87eb3e",
            "d2f5d01059f94fa7a1564dba22069329",
            "4c07a9341e0a4c98a699a8c53732c4c5",
            "59f6395275984bc0ab6965f72116efaa",
            "7e9ae6f317b14418aa4ff3211b0bda45",
            "c5e62a0345b244bcb48064a7e6fbcb44",
            "cca395f745c74f589c95540a5c9b5971",
            "cd47ee03e57e43b38c0e42d7fe4448c6",
            "3f241b6cb5bf45dc87d5f3d9807ea3b1",
            "f71a66fd32dd4296b5f05362d7f55ee8",
            "31db91fea502471a929fc16b301c10af",
            "f540cdd5b88d490495d4a3768c798ee9",
            "33d0342178b246c18f7df5c23fa54801",
            "339c315d0de449a99a7c471dbd78c3c8",
            "c82c7f18ade249cc86d808e051668bd1",
            "d5f1b25b7a40440b82b31db75e1a46ed",
            "25907457c10b44be84210c060d7bb575",
            "c0e509cec1a04720af77e6217a6af5f1",
            "96f07120a76948dab0ff9878facdfc95",
            "96572c7cdf814064815845fb3af9e37f",
            "87c14a53e7674ca992f91728ef721c3e",
            "beee9556413945078e091f358b56ae30",
            "aa5e99cd9b264294a5b76c761cfc06b9",
            "3a490b38082f4d3db0a7168d8dca83f5",
            "ffa0ab1496c54a719d61400d85370712",
            "a11599e5196549e48f311eedc8599c88",
            "bf42bac1caef4fd5b88518029172047b",
            "704a976ccfe34bd2869bf7ecddac5f6d",
            "1839428a70a847b8ad48292b7b6b7c4c",
            "cc81ebde17f2458599e953251d0b12a9",
            "0771e4125ba1439fa23d59791e285420",
            "7f4584745e2b4ab682c4b0cf154bdffd",
            "1095e053af8c431c8cf7cb42861c4950",
            "5387a589b3e94086977039c9058cf0e1",
            "8285d35978a64755a2dc00ef4d410d30",
            "309add8210394aeeb13181f991cee190",
            "3b8d14dd55e042f18fa4d07ba382a742",
            "29ae2bc15c3845618c9dd540566ed46b",
            "cac59664a437426c8953c58e72cebd85",
            "8891de2e73c947bf876ba12d18f9854f",
            "049222e0a9684d9cab6c0d08b2376580",
            "12b29b22153e494c9db6369fc1d2c203",
            "2f68dd60a01649e4a0e7d1a7cddc9cdb",
            "68949f149a4843eeb8746396393792a0",
            "b6ae662b37e34b73a5417c05389f8227",
            "be7d5b0cf12741019aa696307b289d3a",
            "a93d38aa08db4749865b240f0dfb3481",
            "2b90391aa5a14e69a572c1aa2e3ec2e9",
            "35d6978c7f57499591f1e287b8f2c022",
            "268c6ecc217b41758db8c7c1883b4f19",
            "b5062b92603c4b63a568b04bccf6e573",
            "48c852ca98f54302a9e61fa6258cff5c",
            "1a1a4cad1ea04e9ab8fc93897875a5c2",
            "cbc7df3d80d44a9ab8189d60dd37fff5",
            "5d925151812f4bf697700f2c4687d41f",
            "96447f211a96499a82ace15832830f7a",
            "6cdcb65dbb474aeeae46993184bd9625",
            "546083086a0c48d88c768101e6480657",
            "ac55f82dd953406b9fb9c44b8b61ef06",
            "1c394a603afe43658296e8f94afd11dd",
            "0574792ed6a54149995cd50bb440c613",
            "f896b10c86b244ed905a9ad4f8fe5fb7",
            "f80a9b78dd354c20aa9d239e338ee380",
            "1457559ad407426ba8a7e152b2bacffb",
            "c618e3c6a53e4940be12d5c1615e06de",
            "c9fbe47be63b400ba6c67e5bb67ccfc9",
            "f909a3041521416d9ae37842b7c104e9",
            "b8d795d066824c9d8d1bad33147456c4",
            "f7393c8a1c2e406d8cba9ce4aaa45838",
            "1b44d34e13134ba5835db720e94df38e",
            "65728afa9b6541f490c91d281b5f9fe4",
            "ff9fc54ae1dc4ec3a6bee718fb3fb612",
            "088db30a9aff466080f2a48171666ed3",
            "a8e778ea7b6349839e20cf3c6fe6f2f9",
            "d4d7963162be48aeae188329435773f1",
            "09e3f18540cd4163b1d61b3b449f79ca",
            "f29a01a37a994fab91729a4c7d040020",
            "5997f7ab400e4f1b803f62a23ed8b4e9",
            "694bfb32a4a640db8854d504c40f4b34",
            "bed3a3d1b3a34f56b7337448406b41fd",
            "ddd1d7da4fd34fdcb7a047b713a8e4d1",
            "9fc95e15ede84a7386872b52b43f401e",
            "6f65f7744cec4a2ba104435bfd9c49b9",
            "5243d1b72eed4cab9ebee5b5c7224413",
            "0851a9d709af421a87b100d827a46fdf",
            "76f6e8db134f490891d31c1aa6c410d7",
            "b2375715d95e4fe392cd296e18a4f848",
            "774cf10f657c4a60b62292276343bf2e",
            "4bee0158dbde41a39f6383ba996181f4",
            "1396f41309c94be4a4bc97613d06a419",
            "47072b1781d340c581b4b7419d4e524f",
            "f8d74fb72b49405a85a3d75989822cca",
            "060176129d2c49ada2548fda7006cd34",
            "b46cb70a2de144ae9ce028674d933de0",
            "ccfc26fc6b1b4afa8ed8a5b61b938a95",
            "b3d24453cb4040598a15a29b54863df8",
            "7983476f580c49549af9c2de7480c977",
            "3f63d8fef5aa4906a003bc3cfa95d607",
            "1a1e0cc0010f4810a4dd969900930b27",
            "accc30d01b884fcdaa1a6337e3efe9e3",
            "f07b5bcde5434cc2ad538922638e6db1",
            "4bd7eb81d4f741bdbf23a27528011e11",
            "52d6996d331044edbefd4bdc4de9d281",
            "be2e79faa5dc4bd9869146c6fa323a8b",
            "8e6890a42d7341d6a6379855ab928804",
            "c75de428bb354f59a2eb732347ddddd2",
            "53a406f8c2134a52b17c3747680af460",
            "779fbe4fa8754ba5a55892b8e11e1bfc",
            "f71dab782e2d41079d5a9c0ba0d9802d",
            "6669d8d0422342bd8b3c5be614db8b9c",
            "3148be6a21c0415bb6733b6ac5c3134a",
            "aff8ab928eb241d7ac65a3be702795c8",
            "458e56a5e2d1418aa2ec132257ec595c",
            "461ac2773916489cbf08c1ac7d23655c",
            "595cee8c3873411a862101442386a8ad",
            "7fd4325da82c43c18c4a00be8dce3923",
            "a5642043c7744c6e941dad84607624f8",
            "75a40a802e0b4161a1c80f94f43c36e7",
            "04525d21d21b4c648756ecedea095d52",
            "473dc998c1da4a6c87e7e652e2d62800",
            "df76e38914d54a1a92ce87ae60671cf0",
            "6a5541924ac54ca19be13383bac729eb",
            "46bddafb6d394490a18eaac1b6b6b501",
            "b4ee15a0e67f4f7dbb8f0ba8b2bd8a55",
            "9d5fb77299274b14834e22de34fb793e",
            "450a60557e394bb89988cecc599dd99c",
            "67d9e3a545f447beacd03e27ce2ff228",
            "4404c93f546241f58eee1ca45d636981",
            "3ecd41fbcd7b4f06b98a199bbfea8372",
            "c544f5cac38446b59d66dc7ecd5996cf",
            "597deb0181554c778b04ab6f7f833eee",
            "b2f57a75fac543508f998227b68ddd68",
            "e30837eb1b76460694a0ea4e187d2338",
            "3c4e16ad332c483098bd4ac48e282249",
            "c7568d9ebc8f458d92060a05b3d3a98a",
            "955abeb0dcc64a0a9d854daed92336c3",
            "b7206ca8ace443258f5093a84e400e9d",
            "3a0e7f4a046b4fbfa7acb72ca941d2db",
            "5089de68f6be4a76875dffc60ca71e4f",
            "492b7f4f52504628af52d2a1de16077a",
            "e75b6a2df4534e318f4a9cfbc93e6e1f",
            "617c23ffa0884056b5118757619f7753",
            "b595f157e23e49abaae44e6911519670",
            "2dc79156e1584f77975024a5e8cbf740",
            "f8d8fc83a0894d519c3b32a57160831a",
            "7673af991f63491780e4a28a59f8c10b",
            "87e98f9f8e974d9dbbbe4fbafdc74358",
            "6e22a86e9395486aa9d484adba8a389e",
            "14d1280c399943bd9082cd26415ab1ef",
            "25d8f26dbc3a44b3827287e6e4a71d60",
            "b6849f4b848848a8849b2b4b795ed70b",
            "0c96a521c2c04606b05e802ee6d82890",
            "8c47327bae5a4391b6118c2e17dd8889",
            "b008773430f746a2b8683f70d3080066",
            "25968c64ec7840afb7d62d4aa39a1570",
            "7d4e9c46686f492fbb8755f6a9b8da80",
            "460fdc476840407cad5351b908670cb4",
            "7a0e9878e5db48c2b3181192d9b30e37",
            "8444a894ed2847ab9308d9cbe5bde694",
            "4bc1b165dee840f3a3d67517127de81a",
            "6b9cd5d00ae24dc0a063643cc455f725",
            "e339eaf7ef0e41baad5c159d47ed273d",
            "95a0911f85554d3f8f2e64082b9a83dd",
            "3c78f69744b44d3b90783139db959686",
            "ede1310cf253463eb87f639d0b6d962c",
            "3a9a6c86909546df838d467326fdb475",
            "0dad96a633114ea5928b8136de100f26",
            "b5f9ba9539c94ffe9ca3ba56c8e3edac",
            "8798a06afa594dd6b8ffabe4ccd1d067",
            "633bf0a8ad0f4218bef7c063f298e824",
            "f4157509866247e8ab9a7f5a85b93e15",
            "b8a6875e55bb41d5a7f36ea8b0215209",
            "12cf71b4516344feb4354e91f209ed53",
            "42e2285f02d148d89aa731e076260b0e",
            "9fc01dd04de64f958bb6c30f87d8910b",
            "45d2328d82084be8b087a5da4bb69fa1",
            "92638a61aaab4b6bbbfe9bca693e7e81",
            "cee6e26a5c524bd58e37ee81e99f4e9d",
            "06282048ff8549989435a6ebbef0ea87",
            "610f7993b8854b8ab80dd7dcb9d720c9",
            "3d5ddb58be544778bfea2f67612698a1",
            "18586bec245844cd95f65f69ea556b76",
            "368f6d79d9b8477dba23abca6b3eb07a",
            "7f85961ea3da44bfb8c3227eaeb0d2e3",
            "1247addf73c046e0b1f385a1e7faad1b",
            "5b41bd928a09428698c67a8fecc1837e",
            "13d0db776c49417087022f463cc91ca4",
            "ef61ab6bc5394394a108d674b001864b",
            "bdbcb78e4d3b4dd7aefde7d7e9d3bdca",
            "107f82f4c2734653a183c1ff9ceec1b1",
            "c0843c999d4d4c6aa97a79894c03f29b",
            "a90e362585414dfdbf1e95c38c1bd1fe",
            "524d113a37b947f5b7762050d17d6e6a",
            "dd7fece32343437fa57cfca0489d89cc",
            "38b78ed92a2848bab619759e18b7b04b",
            "16d281101bd142ab872d2492c6c85ed5",
            "ef234dff94384f5d94ab9044393bf3a1",
            "70f3f908ef8341568d24cdf7510e211c",
            "25051b04fa744053a37f1081addffc77",
            "bfd5437d90d649bb8df436a384f66d9c",
            "3c3501e231c546fcbf1f80bfb02349b2",
            "a5191e6f8fca49e68e6af155afde14e7",
            "11980b27a16943cf92fbde11b7260801",
            "b3a0ec951da64329be3f74ee6f2117cc",
            "ce0f50d2565749ed9fd7ec8ab352129e",
            "72929f01254f4b6fa6f1efe870846224",
            "318ac36b946343ceb13fba77349c9596",
            "b7dc4aa64fb24310ba39203d3f76cc2c",
            "50bef2cfd148434e906b84fa522a7e69",
            "d6fde3a9464b49ec92edc8b5aa8e5e44",
            "84c8baf8413d456099e75622fb1a2286",
            "2d69bbe2f6c744c39ce8ad2a644af971",
            "ef45eb83587b44989c0dc6ddfd2dd223",
            "d50ab07705d94948990d46f0aee300e7",
            "733c6a4434b74ceb8f3a54c924cee2c6",
            "def85cbaed07459a9edc9009a7a103c9",
            "c7a3b83e357a45bcbe5b93ec95e914de",
            "54122f6705a7402584ee316e537ee3a8",
            "c514cd60b933446ca4cce7b2e8db338d",
            "914190f0c8764179add53fd40a4a1c57",
            "3a554ef1cc154167ad2ac964fe4a2247",
            "f3bd6026e5ef402a96528024fbdc8143",
            "626171ce0b374b15b5cd056c67e8ce91",
            "75fc7355461b49e7a1a269983e7ebd27",
            "c645f26d04b243518a09495808efc9e8",
            "cee3ab2c935e4bf5bf469449429d5a16",
            "8df3b2c36d134e16bbe118d73473c84e",
            "5279e37474024a33a189adebafe0fbec",
            "50d0bb69cfad4d25bd1a6e037d2bc1b8",
            "9d18a2ca3c6645c3804f02183dc22204",
            "f3ae89c1adaf41aaa659b56ad477bb4a",
            "c379ca34a82a48099567c12b0e31dccf",
            "a79c2bd98c504b1baf2537ba25583b2f",
            "7e792725d27c420f85944565968aa601",
            "eddd40e07baf47ff9a231c37245df645",
            "25b9011128c448feb76aa5ea79610cbf",
            "f7df628c96c14b399584c29b2240f604",
            "d4b0dfc99f7640d4be0e184ad5f94216",
            "aaf2dce3f9c94659bbe97149783994dd",
            "3b80de1ce91743ba8bd22769e396d708",
            "550639a9e0914e6480a3a85ce9f209f0",
            "56a382a817f64d938d57b2070d2ff528",
            "efc6c62afa8444b5aed7b27f8a683b30",
            "18e83ed769cb4222b04b16ae22934af1",
            "f95defb7ecf34d4b81bd598eb8c8d635",
            "8e4c6c9168984b7e8b3aa40e0c006ef4",
            "292104c35870403a8c615f0cd5196600",
            "4af2f61bb9ab4743a21d98bdc6b65d5d",
            "99e9bbea1ad3426db0a440b6b8f12ffc",
            "04b2d203160b400595a5f684dba61a2d",
            "5e2820d8c2204ee795127e89bc90978a",
            "10bc5301f489433fb77daf694346e01a",
            "2a90c84a5ca64205b6473f86b4fb9508",
            "0e5b89ce8ad54440bcdfe0f61ac2a16f",
            "c5d544c38bcf4dc6b5508b358f4e9a25",
            "3e589da86c8544db8fad3aaa61392941",
            "c6da1f9e024e42a9b8b795c557c1b501",
            "717e25c8465e4578b0508586fada3813",
            "c64f54b54fcb49fda0e2442c901265dc",
            "a46cf02a15ef4a7884e413fd85947886",
            "bff9d0c2e1a8481e9a2f750a46f36fa0",
            "49c4cce937494baa95e91ffb46cf3be0",
            "a2ba629e6db24f058ff0a5dcb9afb808",
            "4966aed873314631b737084721fda7c2",
            "2177ea36b7994aa7ba106f85bce454b4",
            "bc7e3ffe75b7454cb9487f67839907df",
            "6ddf6f997788421a9165a4207424bd01",
            "e39fa1f5dc074232890e588cf394d5ff",
            "f1aa4a6086af4706bf44e638fcbda612",
            "ae190666e08b47e89d80608f69dcc9df",
            "a3566112627542b28a5afeaaf62f5acd",
            "15615831387f46b18a90908956c00bbd",
            "21cbc73207284444b71764ba08fa4879",
            "2c096576681347cc96f7e0de978d4246",
            "4a47aec2e01e452da87be1bf6148c82f",
            "895645e8832e4570baf2000db34e95fa",
            "2e8d5afb5dba441297a94ebb85eceec2",
            "44c5278e5f004aa08de9fa1210f0d046",
            "3e7dc646d5d74dc3aa6773229cac52e8",
            "bbc60fd339424d909af59dfbd306123d",
            "d4abe7ea12e7489b95a199b7ed7f7ee0",
            "b91bcdeacefd4dfbb239c7ac7dbcaaee",
            "87d461cbe6714454a058ced2e5dddb57",
            "7fd8dea8c6c34969a53db92bc7397503",
            "d4c600f6ceb644e8b7113a9153b2df30",
            "028c429ac0744aaab740bf0790919fb3",
            "60b70c577c8f4e948980c619e0a078ed",
            "5480f0b0ad9143059b517051290f8279",
            "c69e0d0f614e4a648d48f9e0d9233d70",
            "44631593e56346a5b16d0c71e81244c1",
            "bfe16dbb9cc94cb1be292cf49a5ebfc5",
            "8b749bfeabfc41ea811a55723743c5a5",
            "e0deee76b00c4f788b6cc32d7da6d9f5",
            "2a9813cc492042c48942c25dac47e2fe",
            "9e46132acd314b19bac6a12b441f6043",
            "2c0100b6498e464a9f743a7d0683a492",
            "eea4d74b0a8c4e87a98d05977f0de636",
            "1b65164d5c124164be0b58c92beb79e0",
            "eb78ca6b1baa4402ac94177d01ffd2a6",
            "b76b9cb00735414c9c82d37e3b2f3e3e",
            "e1c1d476766f4e8e9807e6cca2e8a3d1",
            "8af02b0c1e4c40bcac506baf6aa06362",
            "80685ded8c744e26b2e65ade1db280b1",
            "180dbf33401b43f78f5f4467a393355d",
            "8ecb10e058234057ab893523a80e12d4",
            "fca9fe5a49904204b3556dc17d934251",
            "f79e8ec234ae46cc862792cce11b1045",
            "11410cc32b7c48b08e2251fd4c35cf5c",
            "8ea460e579a44876a44e1765619339ea",
            "10268f67abab4c44ad9dc41db649ca6a",
            "01993ce7871c4aa3a73a3c36b8c614c9",
            "13b015e6d893458c93ada2c529ba5b3f",
            "a9699a0953dc4b9fadb5e7c3c2444d5c",
            "4b13397084b649b8a7b24c970e66bbc7",
            "e133f73f34b246b0b7481a236e13b8eb",
            "b2e07d0938da4ee6820ee6ff8d0600ac",
            "e396b9dfd1c943259865f9860485ee70",
            "394ed17e97a145bb8ed8c4fc85ea515b",
            "027346dd8a4d4ad1839a7832e68bf550",
            "4a18914a1cfe41b9a0bd75e04362e0ba",
            "3ef9e9784b814838b978f22f4e7283f9",
            "0565bbb218804dbfafc208730354377e",
            "9e2ef8ae2e97408491492181a44af0dc",
            "407a60283df742ccae9f636618c67a4a",
            "a9442fba065e4dcc868bfa8f393d4bdf",
            "24fb9ec9ea5945e68c109bee6dce0676",
            "1b91db077ff64f3690bdb49c29856b3d",
            "32e1775ca8fc44ddbb0e0dfa363c5dc6",
            "6f6a300e523d44feabf889bdd445c0f2",
            "04031f75f81849e080bbdb3eefbec67c",
            "c240cfcaf0a74b91b73dd369c465058f",
            "60a6ab8ff418488cb1dfb090f136927c",
            "2b8e0cc7cf4c45ecba0ce605df824153",
            "52cfe02439c24cd292f91f053b039d44",
            "8c9ec6b66be54e10a22ad2b6536ac707",
            "c20c3944912845ad98524553fb760f14",
            "a01643f7cd834daf8efa4001644ba49f",
            "b9797aff2f844bbe845373c4e0865095",
            "e864947101d041889b778ea18ef4a75f",
            "6181c0d5b6be42e4aa8d252a9b9ec8a2",
            "16bc99ec929b4ef5afd05e20bb5b5ff0",
            "81f9cb7a20b64ff3934403fe944946fb",
            "caa77d28d1ef4e4686d9210780d1f31e",
            "de7fa4dae1064d9f9999f2102b7ba716",
            "7e05e228045d4481b179d11303b8f24e",
            "ef7959fbee924494b18b92ba4f52ecde",
            "0e28db3422fb45fcaeb4a4d7ebb20288",
            "33cdf03d7d514435ae855aad4250f67a",
            "f92e18d5d37e4f7eab4482790e161f48",
            "91b5970943104f47a881f1c03258049b",
            "5809544890c84c478d4f45863cfb2eef",
            "23a4b5176ad2474ea1a5778ac99ff4f9",
            "89c81ddf72504f17924ff92cef82a5a4",
            "8bef2d7e6edc4e09be46dfb91cc1b859",
            "1c5b35ce47b34f47b8f8868ee54cd4c0",
            "1fdb42af00d849c2aa95b5f9b092d5dd",
            "a9e895968d1d4e3396ec561e5a82ede4",
            "46ecbc58bf7648d386eda69a149191dd",
            "aa36c0d18d0e49ab96baa6c7121f528b",
            "4b9cd63e2fba427989099f1b9fc9e262",
            "c1cb7f6e15484687a5df6c415d2b152d",
            "92f7d1b81ae848308b5adfed48e8eef0",
            "17c0173bfeb14142bb35422d13f18546",
            "18c9ca074cee44c88a1645bec017e1c4",
            "e5c42a1457064e41acd40b126f429e07",
            "b2b12174ab2946bc9b0b2fcb0384f12f",
            "08196164a5144d76b04d77fbfdc57da6",
            "0f8c28d5ab744054883c9522ed642180",
            "7e9b21010e2a4bd8b33cdd2720c475f5",
            "228f296e942144aba158fb9e47c9e700",
            "de9c62109e984dcc9e91c5503457704a",
            "51a939713d0447aea8083b0ba86254f2",
            "31b4e36bec584787b4546459fb011c75",
            "21d940a3351c4da1a5b16da4ac0e669e",
            "ed1edc2c2cdd435a891656f6f3dfbb17",
            "064780861917435ca9e47cb8c26fc02c",
            "684ee91bfa6941de8a76362b45d76d2a",
            "5b30abea29fe4c9590e8630b76b35ffb",
            "daf13ce0321a4a4c84b5d258c01d4583",
            "682164907ee3411fbb44771d3a3b2a90",
            "b525038488854cd287692a334874c316",
            "a7a3f86926bc4b299233af42f2fb1b0a",
            "799492e6a1e5410cbd1fd71b9e5be32d",
            "a36596bf671b48d6a671153fc7f7dcff",
            "5b2087ff11b54337916aa233e253f69a",
            "d76c28cdf13d4f658cdd8a891a151811",
            "e8c4e9548f4f47e2a2cc2ead0e120d7d",
            "77096596d095414bb6d4b5fbd4d1766c",
            "d6c8194ae3a4424e8f3e74521ac841fe",
            "c9a3a016492f494380a370752e77446d",
            "d7a1485d25954b7f885337be22980cb1",
            "20a73093de1e4a6bad4fe58627120702",
            "31997d08b9864a05a9f86111cd01f19a",
            "ceaa60db72494be886ecf06ee73a883d",
            "796c9563263b4ba5832a87af87fbe6cb",
            "1d962b63e9ef4b39b092b59eec141429",
            "a221b2176ec949c5a691a44abfb959cc",
            "edf0b1fe54264d3ea3d09c50f08a8e98",
            "2f7ca5f7fe364c1588374cfe74ee3c92",
            "09a72096826642ef9f86b34624f70c04",
            "653957de197b4d48bfd061b760237d10",
            "3a07189accf34fe9aa0d66980fc4e470",
            "c97aa1a8a87441a4b38d35059413ebe1",
            "e2f10362e60140a99a2132fc777f512d",
            "c22b50be5c4647e9bbaa9c9b292065eb",
            "bb9d2727faa64576af1e65d65461fae7",
            "cfd125efcd644ea2afc778accfcb82c5",
            "b62badb8b043455da2c1dddb76c0be6c",
            "60e5d9fdd3b940ca8303ab6d37883b84",
            "05b2169892324236bec9c0b04584f555",
            "f855cd7edcf54058b989950b015dd84e",
            "d9e860a990f34f6e98bd755065407918",
            "426c7c6afb90463c83552a4156790490",
            "d58e5ab01d3945e1a203763355d8f212",
            "85703a4c2e9e4c9ba7482e97562bc9c3",
            "b6b32bf75bb34e25b534c29ab5753713",
            "02140bd390694ee396b6587fd337f6f2",
            "e92d23c2ada84dcaa9a3f775e7f8a5f4",
            "7d2010f459c14592ac2dcae1bedacc5f",
            "a4c12339c8504289a428064aab07a9cb",
            "7d42b01d93ff42089e1fdf99118074d7",
            "77f95caed09347ad8cc96fce357a31e1",
            "6a50e229e2a749fa95126c08606c8b65",
            "49860fb6a2a54497b83b99eba6561b80",
            "f631bf5a0b7143419010b68e7d6aeb92",
            "69b6731a546246db9c1d733d6c86933a",
            "a115ece6154e4f2285518ac7b62a3da6",
            "fc00880a34844ba686f6060fae17b17f",
            "52d4ad8505634d8fb4630da30b1f5925",
            "b0d68ddf26364a63b0d38075d0e67721",
            "964405454d5448398a9dd9b80748371d",
            "411a1163eee548a6bda79cd5d59141f4",
            "4764c32abd654cb2a2c598a00db325f9",
            "c5f05426678f40e3aea07b00d56fcd02",
            "eda930141c614c1faf4367f1d68a1364",
            "1913d6bd39fb4f5c95370ffba7ea4876",
            "6cf7a403c09b48b49c116f697fae7bb8",
            "a8b278710d2c40058e0375d75ed1b9a8",
            "7a7fec82719347d8adc61f77f64ef231",
            "6ca03f6a83ca4e269e1d583619fafa44",
            "b8a6107bab3b4546839bda496afacb44",
            "9a903276164c484394be490833fda854",
            "baddc5c9d5d545aea1a531bac2d6bf5a",
            "ee1e46352d704609afa9d28c5172034f",
            "b470f34e86ce48829b53de9f62f17436",
            "d5fbf8a39be94318ac28a77cc84147c1",
            "1e6084867b364be697aa2dbc7f9f3909",
            "4265fd090cf446c3a6f06027ee85a472",
            "265d5bc7aab64a1380d7c218bc5b52a9",
            "09b41ac1b7c7410ab7f58da1e66a8d22",
            "09edf3d18c524e30b997e75e03644db5",
            "e87512e90f584e56845ad4a8af77843f",
            "79e5db5594644b5da4268ed16b4c8aae",
            "3ecc4e5fe4bf46c8b63635554b71d7fb",
            "9aa090b20414468c98de26eabab881bb",
            "f227667ec93941a68848e03f812c04a9",
            "ff7443f995d546d497148b5636259b99",
            "693b0cc2f36646ea895f5e78877907be",
            "000ff96022be4c7fa15c83b0db157406",
            "fdc4b46ea3e34da1ac399b64b64db1c3",
            "1dccb3291a8048c1bc2bdeac373f6dfb",
            "fd93e0fea3b54247a2df228483271775",
            "033c1ddda4fe491aac8b1749991e4ca3",
            "93b19ecbedc94d1c889aee20ffb1f794",
            "8daf4fca98a54f9ca865df6469c4a91e",
            "c2a0ac18fdd7423b9df4e0a59eb74cb7",
            "d39e9f3d9427452cbf879ca1474741ef",
            "f055da8f8be846c98e70e97d06f62d3d",
            "033fca4857434f17ab6ab304a583e41f",
            "757c4d82e6f7422c8594a988200d7467",
            "ecd66c88b93d49a28eca28fe8f7bdc38",
            "6b3ac82a346e4166b764be9fc551578e",
            "cfcdbc63763d488e9c0207559307fb0f",
            "dc847d78cccd4657bc584b4bc240352f",
            "d959809d257b4a43b9b470791cd70451",
            "fbc313731c894abea4cbf8275c78ee3e",
            "17abf33eec784c2d905e597d325e6c4a",
            "1440d67ca86a4584a3e9d738d5530723",
            "da739a33d20842aeb302f822b69c8f63",
            "85af8dd9a36143a08df1404c89248b6f",
            "53cf6306c2e94ba3abdf81830eb00c15",
            "4222a2a41df045f980591d48aa258943",
            "6aee3e90ba6b43c8862acb82f772882d",
            "625a74a2c572433a9de487a96782401e",
            "4d66470a55ee4d9cae49d5768c35c32c",
            "9362d30208ca4227b0d909767e3977a9",
            "525f6735db494e4094b8530968767c4b",
            "fb6e217178594691a261f7d7f7518365",
            "8a71ac9be38443e0b276674dc5184a29",
            "2e9752e2fa4f46288fc3dfc8d6a2fb9c",
            "400f8025fb1c44c48a241f7e338ded3a",
            "4463ef9dfc1a4fd6990120a8dc95889a",
            "179c5324901a413ba7692499f824828c",
            "496b68565d9f4907a0474dbbcd54bdee",
            "60c7f767c9b24f58b8a8e31ecdeeda1d",
            "2e7a3362c8294c73abbd5af638e8f2ff",
            "65c1b3b172454c7b88ff47c1c6d13d0f",
            "6041160690ff4113abce1b8aab297474",
            "09ae8f9f2dbc4251902f12bacb1d44e5",
            "ccbeb986be94430da50c48233c294497",
            "6188f1d8f2b14f8e98cffb1bc909904d",
            "e6d39f8dfeda4adfb3df18f36ebad298",
            "66b3a91b7c674b9a8340f61c243186c8",
            "d883d032f8c4454f9b1e381fec614239",
            "fcb015ae3e0042e6ada26fe7c3960f15",
            "a5fcf2130d024fe3a8d7921badcc9ae7",
            "c137c67d16474645bec01a46d71727e8",
            "dfaed2d4f2514f74b210808ad7a8c649",
            "b6acd667f5d54de893a05d7d9ca354e1",
            "7c1d04ae6b6b4f0caf8f727d5cab2363",
            "9bb556f2488c498ea881834b551a3117",
            "925328624cbf4a04b307889894aa7e6a",
            "4508bb448e994946b3dec39a933bcadb",
            "88963d919dfd4b7aa59f89d9a520de05",
            "8d14076489ff429f89d8f89811e00f49",
            "7556dfdb6a11406cafcfff9337040627",
            "039cd8e4c90b4a6b954a93a62bc69c92",
            "9c32eb15f0b644779623f99636f9b3d7",
            "344bb2d56b514e5387867ba14b52e8c5",
            "e8c714d13d8e4711ad866ec1472fc159",
            "757fa89f7bf347139bef9161d21a5c74",
            "1508abbfa8784cd3b21d13ac3c3c51c6",
            "f6cca360009d4c85bfe1f24e6e2e8d35",
            "c4a5832a306c4c27a6e16ee5b71ce517",
            "18306bb1e710453cb7ac96a7f744ad3d",
            "3ef1be509e6d4cd9b1474f83d04acdfa",
            "09303c7656104efda42fc91960d6ed19",
            "68c24f6679c344d0bce3d2cfd68df0c8",
            "a753d3a169b346219eb76bfdc69ca3b1",
            "1f7da1d8574b4e2db28be932187bef4d",
            "423aafc7fc324a75994324bff70e83bd",
            "0a966b44af7942a68c55d63ca12e6475",
            "923bdf77392241d9b9e325f78231148f",
            "4c214c2f45be4a69bb53d22ed3154700",
            "b66b03028dce4d779be2c53d243fb712",
            "9434bd80aec64b3dbebe169c9f365310",
            "ceb3ec89c812435f964c5d2deb498980",
            "1c02030675cb41dcb1ceae0577972a7b",
            "5adfbb3c0cfd4b5fa453f25b865bd122",
            "94a33c65a8764249909673a6ae003d6e",
            "6c7a20827e9344ee879d608b8d59015c",
            "053eb2cdb5e64deeaed40d85e8a0f6e8",
            "d89ca9340f8c466ca18ace256c70c0da",
            "97750cd7ace24bbb972d0ae442dc2c12",
            "d5887779b3ff495c91fccbd0ce025ed7",
            "2597401ed501484eaf204525058e908b",
            "2729937a8ae14cd9967a1b077afd5d03",
            "9597a1a2ac3e403ca98c562121372f77",
            "20ef3bb117264e8f88e96eaa4f49daf3",
            "a06757dfcc264489897beee88dcbc9c8",
            "9b526c293ead4aa5b92d2cc9d2219ac0",
            "ded881564511405a8b901e689237c15f",
            "03a853b522064ecf8adefdfd459cdd89",
            "b346c48a7b9f4886820713188a6b23b9",
            "65c98be175df4c9faff60a95bb3bd00a",
            "e963a025cc704f2eba61e7d1c78593f7",
            "5c3d5e18ded54ffcb86f18411395c820",
            "1fb9731e5c9744e3bb023bf216ea23d7",
            "f0c965206c034064a7de52a1302d59b7",
            "acf1c95af6eb46968b684998603f9cd4",
            "46f9f36da7b64304b4b7fd0516831727",
            "2a72e01755884d92ae9f254577497e49",
            "640248f64c544643b9d46c9672b035cb",
            "f4a3e5d3d26a41b0a184d4c7e9568a1c",
            "b405f111ebd14c0e841028dceb95dc81",
            "64a299c8ed1d415490ca359507a80366",
            "ed0d4917a48943a2a67cee6246132cb8",
            "b4077ef04e8c429a9ffd61b7b9b4f3c2",
            "1fe5c05e7740403f9f643521aee9f286",
            "2287042fe9df486ba9cfa444f35e2d76",
            "8aa4f69f7eda4fbd86a3ba71c9164157",
            "b8d822b7e92546469d13d80e09fd0870",
            "9360eed045014a30963cc1d53421f357",
            "c3020e27b7f04e37bbe8987e0e7c5c11",
            "ba54e77f86864960ad1b35c8b8d7684f",
            "5d226ab9e660407cb9b8b130649f8b4e",
            "b263bdf7456a417c849717bf1f787be6",
            "f3ff8215d68942489616db39f54f26dc",
            "7ea6842eb2224bf18dc651a7358d8fe0",
            "ac1fbedd83c74d5ebfa60de323a825ed",
            "fb4ab39bccbf44e3b9fa9aebe0886d2e",
            "bc8cfd3a309d41f880efe5e1ceadc6aa",
            "f1e02b50365747d68d29b104ba262c99",
            "2fde36ff99224649b029f4c1e7361f56",
            "f4363232e77442a594cd559d19c93e4a",
            "267446d14c3e4707990a4b62e0d714e4",
            "bf96b86e644247e1886930c5bba78cf2",
            "f6a3432875b24dfba283aa6d3295ff23",
            "df423a08440f4522882121751d7fe65c",
            "f32feb3abf134b7a872ed01de8677e35",
            "93bae0ba20a44788b18bcaeb6589acb3",
            "41d3d4f36f874ec3926946bb444b32c0",
            "148fd7ef7066466ab237f9a31627a179",
            "471d51eef49841879e58f0aaa654cafd",
            "ce383d2051d94aa8839c3aa4ff31e6aa",
            "b9088a1de0c4443681e80bbed726a977",
            "9855ca58a4b443798cbc95e7f05d1d35",
            "1f4132339b394a45a26cf2142658fe17",
            "a54a1c88480c4acb89773b00772bdf0a",
            "fcd81c2bc1d84f21bc9f792602156284",
            "499b0a492fb346ff8d961b90410a8c8e",
            "4f6bd3f889a54d4da821b2162d7f27cd",
            "ab1b1d0d6b4b4a12bf12b99d4c07de4a",
            "54c3be137fee4a62a3998ec1572da187",
            "b6bad94dc91a41089cb3f4b0ab4d99e7",
            "1bc0b7c223c34040bf272e408e61cb14",
            "056b89ef96ec4dcd86fa82015bf811cb",
            "8572e30bc3c6400a9abf5f9771d1992a",
            "ccd8cf3958e04985a7c4bb9bde58a1f4",
            "4b9109eb027f49e187937eec497e980f",
            "e28fd4414b5c431d9d864546c2de6d55",
            "9dc8c68f34824571883b5db1315eb750",
            "438d62aa87144cad80df277febfb6c5f",
            "f7aff3162c314d85a8cb93edbe2f8274",
            "bec15e7f9bf541c0a69207dc83543ea6",
            "b1e7a78e9b394257be69f9b1c7b3aa8a",
            "068adbb86e1944ebb989b2c2e1595684",
            "9c623c7977254c0e85daa77202ce414d",
            "c7e2878e317c49dcb605af6bc7a7438f",
            "72ec547daab54c23a352fd2d2af10827",
            "306189ab030c42a6b391291fc897b958",
            "dd48153e43cf4e52bf8e201b1b75a281",
            "fcd2fe52772344a3a0e7b7660e7f6ed1",
            "bd4db0fc8b994a248fbff0d08a8ba191",
            "3acae434882c46aeb03de9cc689df4cd",
            "4e7aa393dcc944e6836f2e7d6a24dff7",
            "2aff26fac75241858210fb4bfdfbf1a2",
            "189e3904307643ae99589546fbde21c0",
            "815bfa22f3e14b4da5f1aca91fc886fa",
            "2dd43c8611f94d2fa04ac33ad4cfd4d3",
            "94853745764148a39c33ea3af391e96d",
            "9eba7e6ce7d1456e8c8bacdcc3b2a652",
            "7763df010bda4fa09977a142cf791ed5",
            "1bc0a178501046c4bbdf1d0482608d69",
            "cf50965b9eab412d832f361fddacc7bd",
            "f3530d0e40ce4fd287a2e56358a95acf",
            "2986f88d947f49b7854090a65fc717f1",
            "cf458ebe2b6a4512b4aa047255f88e97",
            "47aa6e10fe704ec4966e02d34cc485d0",
            "b7ac62c9c6134eb9bc94ada58c2d3626",
            "1f591f0718134c538942045773707626",
            "1fd092bf87a9412795d24de427e3aaaa",
            "6a06b6ee16464159a4d1602f50fd683b",
            "bb4611f533a145cc87182982561befa6",
            "8eed2a06e9004126a77a0f1e39f42831",
            "b42ec1ada1e1499f868b5b2fd1b03315",
            "35aaaf8985de4ce695fc84b342703982",
            "5d508b83be9d4523bbf0f8d907c251de",
            "3643d8cfe298478c8c1894edd5d44897",
            "04a18d89f7784ca3b0ada02351f3b919",
            "e0e21a4029614882ac35ea8a7fcad544",
            "165076dfbd964275ba6a2750383503ca",
            "65502ec60d5044778ca606e88ae061c5",
            "889573988a5c44cd923fae6c580ade1e",
            "e4d48ec016f843e688226da85eb79d1b",
            "642d635e7d184af286e657d5aa2c1cc6",
            "07eb70bea1e0485488a146cde8adfaff",
            "994f3eb4115045a59db7695418c3c4ea",
            "c85ade4573344dabb0a8170e9a8451b8",
            "d1bc98bdbe1b4ef9be296412ae192fbf",
            "8eb8ec9895d649c7bc65d35ca829ac26",
            "9b0981ded75e40df8309fb8c16266e43",
            "103b6d02994f43b69b225fc9c512691a",
            "989f1907f567458092a51ff340c013dc",
            "d3056a9e8d474b3381978d58d53bd40c",
            "a38f6b0436bd4a769385bf2baae901d0",
            "edb016562e844882b9870eddc2a3bca4",
            "be3cb1b18f3448e4b6bb0eaf05b15910",
            "db2f3166e35f437396cc8551667a7753",
            "dad15b7c377e4d26a4653ed446300678",
            "3ddf0059564646b5907c53a6af92f115",
            "653bd9857aa841489eb2dd2caacac56f",
            "49997baf3f004594abf26fa1a3364362",
            "b20f86a5b5a1406faefa0623f4208858",
            "83de067845ab4da282c11f8840f0051d",
            "ef5e7d7c6bee48739323ace62fb9db68",
            "5ad45ad45c8147568fd52480fc06bf7e",
            "762a4ac608724534be34b547c940e3b8",
            "325d7b25c7cf4f428f0a92863c3c60b7",
            "e93815e9898a491e9041855f74fadd39",
            "298f844fd98a45f08826a13bbf8bbb8d",
            "627e5dbd7a964b98a19e69faf26e7663",
            "55f8488c23404730bd2641c2e9128813",
            "e53903489ef14ced83acd7fd133701ee",
            "f5c6374ff0a04f65b3c3fabd8aa2498c",
            "6984c2ce3b7a4843afdd4d89c33e8c65",
            "09f859141f7142e5871565434637e0ab",
            "21ce74fe9a4c44a2ad7b858d938aa018",
            "036d865ef6b94898aab92494c55111e5",
            "205d47a37d94464b8a96cdf0edaeb47e",
            "f79c126414e7417ea3c53cdf5d96a1f4",
            "e75a6b4d5b84439ab838e19145ee3261",
            "69a60bebb7574d96b9e9107feaa39070",
            "96aa9aec165c4a219f4bd896c63a2048",
            "5c3aa0c1eced4b3f987451c345df3fd3",
            "bf0edec3180d4bbba2be8bcb32609d3a",
            "d66b905be77e41d4bcf3aae8013f9de2",
            "068a67f4c79e4c1889f6e611a495592c",
            "67fcb60126b346598ebd92294be9e454",
            "ba09b8e675c6432d906d22dd5d604acf",
            "3f52a28e834d40b3b7ff8e39883ace3f",
            "06982e1828484014a0b234735211d4a9",
            "9b2dc1cbd0ef450db4b903386dd80028",
            "a5d7355fd7924155867cdd5a3bb00826",
            "64cd89733333460b8753b9a20cacf840",
            "10c3da8bd13540f690b281f7f6e80eed",
            "8ab8a4e4194d4a2e8e1d0800ea37362e",
            "540911fe9d5e4b59bd6a3bd9cc7a607f",
            "a77841cf242144779879c9ed10946911",
            "8cfb5dc7e9f44953bf2a8db110b314e8",
            "228044211a8d4fc9932f8cf3b373947e",
            "9676be0db5314915b48d3de21f9dd8d4",
            "389db2d9cfd442a092588506e4c0ea72",
            "1afac78fbe4f43dba33b146e2cdb6ee1",
            "0248707f5c3e473a853570e0a4c3ab63",
            "f5694b1b9bf14391b3c61d2e7847211b",
            "215757f0139f4398b89e387c60b4b1f8",
            "3a1e6a9ec43241528d490f3771a16f2b",
            "d445f5aab6f3496885b45b314e093d5a",
            "81c5b2eaff524d53aff1d862ecb9140f",
            "11ff09c7f65c4773a9cc9cb66ebc8e67",
            "eafbf4215d384bfe9ea574a1a3be2066",
            "e2d9b1aa388f4bf4a47d93e65eab27d6",
            "7ca77a01d8894e089de996e3b710400a",
            "d9f9f24c4d9744c8b243742423003b43",
            "021c3cc5520045dc8d8fed406720ecb3",
            "fba8f466a7b146c7ac5cf97850e45631",
            "59313cbe15794525bd59d9ba682994e3",
            "07541865c0b54edf9901a3eab8ad573b",
            "1090b5b435f8425f985355f7ea9dad37",
            "7e4719f3a4aa46af9e4a1e61d4b265de",
            "43fe26ed24df4bbcacf8deaf47f699b6",
            "927c2f46146e46e28b4a3a30c9380b1a",
            "6a5ff12502ff4e3abad6f1d1862594e9",
            "ee835bf81dd841a4a515fce4f96cbf01",
            "d8c7874e5c494bfcba070dd5c318b48a",
            "118cbbec411240878f5228e7365c0551",
            "94087397c19e4c838017abe65c1c9749",
            "45082b55ae6040c8a9f460d6263fec4f",
            "d7b4fc5795504880a71b54243bbd0960",
            "2a9e07a95d4d4f998263c6ec53012b73",
            "fea5a5416840462180dd3d5290cd7585",
            "c902fe81f6b54d40a42ef79eb1dbf669",
            "b70c77f6f3e04a3ca97a677ddbcb8570",
            "8a86bbd9fc1f486db227a684da76c0b6",
            "18a9403f528a469ca84a6bf75fdcebf5",
            "67b7b1d58a4b475283dce61425928ec1",
            "7a26993964b2402e81306ab1ba59669f",
            "08c4e2a357b845d385b72c526518cb29",
            "0e97edba18ea44cc995099998dcdf2de",
            "f1176139b3bd4d8ca51fadcbd01524d5",
            "420e422e39a647a1a36be232f9070cf3",
            "32c7ea2f904b40d48ca5baccf8d2e8c7",
            "a0c3e5bc584444c7a4775bc0c2dc2972",
            "6ee17cdf68cc42359f01f0ca2bcea543",
            "e758240f6b95466d803f37d9ee24bd88",
            "a3d3f1370dc34504a32401456e25d93b",
            "6328da1f7ba94a28bfe5c0331343aa97",
            "f9eee0fff11046458e46cf0e88cb1157",
            "03e9c1dd1f314111bb3e894cd21235a8",
            "96307e3710ed4c94a195ab70c130a439",
            "a9284112aeab48968318b034af919637",
            "9f6d6e93e0144980996c3d97b507fd1e",
            "0f150fc2e1b34af6b34c0cefc438a6c9",
            "5dc9b34d16ea499d9dfbd6f309cee08e",
            "3cb6914186844b3982a61b1974913505",
            "da768ce9f1a249259411790b4c478195",
            "30312ccde7c74fb694a4430c23341552",
            "29010b7d3e2d41c49ddd7e16883b61a5",
            "23e302e3e4fc43dba1ad4dd8d93bc147",
            "5607095edc054a9b9adeb85d366f03f0",
            "071181d3a8c44587878e7117bc8433b0",
            "2bcc657decc74db98315862f2d6ae286",
            "2c0d296b7bdc45338c8bfe4281973cc4",
            "efd3f9734793486ca7ed234abfce9558",
            "125928df48b148c293c97f0fb4d9f753",
            "033d6b75eb094ce2aa5bf9a46b8b5a11",
            "d4468ebbd54242ad93d8573a149cfff5",
            "74eccf36ac074249bb2f9390026996d8",
            "eeff506a5af2464095152f05cce3d189",
            "65610a5f3f6844ca9e2b0ff9266d036d",
            "0edbfc856d424c66986edfd67c36c359",
            "f7a1b1c886a64d8285455eb40914d9c0",
            "e54301c83fce431ea87d528d5cd90737",
            "7dea3f5efe1f4ede9132e71c7a709b0d",
            "3fba971382e14a019db7e16281b08231",
            "21dc81c69fd94659b4286e05698b69bb",
            "6264a0a6781449f3a27c07bcb9811043",
            "909ee88e2a3243c39764f8c93bf806b2",
            "878c6a2096314eeb9453ef8f483985b4",
            "bb4cf9b09bec4bfeb8e78fc68347e2c7",
            "4c5678de7fb04cea9f9a5668435a7d9a",
            "3a844ef06e2249748635e9278832ece8",
            "3728ab78e7e948a9a4ff7adfa24403d6",
            "edeba06a3c8c43a083994b1f6a249dfc",
            "beacb7d5fb954427b9c5ce1dbba875d4",
            "40e2d41887c0462c9bb7cf578851502c",
            "614a85d1a20846058d95a138351da1f0",
            "be66368240ad428aaea557030784cd45",
            "df856ed404a4477cb5e7bef84dbf645e",
            "23af67812e064ac4b0a094c4c305b7e6",
            "be26ccadf1fb40bba3e89f9a95d8522e",
            "2f5c7a523f8941289a5cab97a6f8c5ea",
            "d3d834c837c14ca2be2a767cd95c451e",
            "7f6137b13b7f45308543eaca8f2b958e",
            "9f88101ce7684cb0b5ad7ee6eba11daf",
            "bd628ae6ce9d43228de568c5f353cd35",
            "90d7f7adf85547e59fd7d28522417858",
            "8fad94daa29846ea82b33d97de445a7d",
            "59c54caf78684e3b8d07e83ae8d97a66",
            "7e2362f4fa764a94a91100dbe4d12af2",
            "96b1fbc89c4847dab516a154dd6ac189",
            "dde2911c6f64409b9b98f2fa986e2886",
            "def3544386bb4747ad3dddbc14ae9f6d",
            "697107353b16469c92c4b303301f5316",
            "af8f9496c7cf4537b532a3d61d061ca1",
            "cb5d51f8c5ca45b281a96f7e2ed25e5f",
            "524b804c618948aeabafbf5bac4b18c2",
            "b83f88a29f7449f0832bd0c55f8f6327",
            "e7d1708a22674de7ae9c08a9f8374362",
            "4c45978514c64ddb881d56763459a442",
            "a8c492c700704197aa67be1cc417431e",
            "5b6307471f844207b5468e94edca6ca4",
            "2970480487fa40759643077785a0d29f",
            "e280216b0af34578a76649707efeebd7",
            "b05d9211daaa458fb3c8a17e93eb69bc",
            "7e78a2e6a453460a8488b0dd96355ca1",
            "735d9d0b9fb24720bb65a27474a626a9",
            "0ac404232baf457298c53cc09dada3b6",
            "afe92eb67dcb494d9387433d47a73bf8",
            "a457ef9bdda542808fa601a71ca0b6f2",
            "bea40a17b91943a8b281b506df07ab39",
            "b51886cd7f704dc2a2d8b9d7ae8ef030",
            "bb687f73f8d14ba79825a3a9ec0cade2",
            "184b7a3bf34443fbb7ea656e435613de",
            "168ea69133d54112ba6e6503d8654ddd",
            "03bcc55ecad94945aa62e0756f701759",
            "ddefd0478fb04364a7f21b603bab3888",
            "beff438334e94236ae0ba4cb9b381d8f",
            "772a1a6c4794477f98a678635f34f34d",
            "f0937bb377b24239903aa5037087784a",
            "0be3f86aca194cfe887a0f02beb1f686",
            "d889abbdde02484dbf7b62a934459d50",
            "f6b3c5c73f1f4ec59affddcd4228365e",
            "ba36d105aefb49769e5cd43e7ed9de74",
            "6601c5926b3d431d900913de1c4dd37e",
            "0f97b23c83a04cd99932f978e036b4c3",
            "d40a4d7351984b74bacc2120818e9e73",
            "6ab3fd2491974af3a2e3cb70330ccff8",
            "5ad25d14d2ce44869b7bcbf0224abe7c",
            "8e46c30520c146288f09c28f6cedc5e9",
            "2d7d9393bcd048f289ce2f1743d89e0e",
            "fbcd74623984488687145425c91db884",
            "89c1c0267925466697e347955e497379",
            "6cd5cab908d543feb24e202f101f493d",
            "cc5dfe2e226f49b3ab70b5eef92b79d4",
            "8c5a0afee21b419cb16f793f616d6368",
            "9e95a579a529446c810d4330513e851c",
            "923c8e6c0dab4d789c78b0c4bf64ba7f",
            "85ae544aabf248cc9a58d673e835f4d1",
            "4e06f8208e3c4eac8fef1fc250c30cb2",
            "a7e2a7a865fd448c97ae1bae8a6c449a",
            "0f131bf659dd4510af4b2854377e2f41",
            "5d1cd84f7551479b995a499985d466cb",
            "925a5fb74f40400fb7461cfaa87102f4",
            "3eb5e5a7cae84e75a282002131147699",
            "e6c32cf08580476bb185a694101db1e5",
            "272f27f2209548e3bd71a97273d1bea9",
            "9b581d4692954bf1b3babaf1f73d0447",
            "cf7a6dc415384fe1bd0c5c4685be1393",
            "1ce122fecd314ed9b474db43b3569ebd",
            "6c4358cb624d44808afed990f8c2272c",
            "a7718cf6c8594425b7fdfaeb4ac7b285",
            "c6fd9b0fac8a4e20a26be79403d25cd7",
            "45a2c7f365dd42ddb2bc6b08a4dcbaea",
            "7b5f56b01abc4107865ac2fc5c3ef54e",
            "b622d0f2708b424ab860719fc3759ea8",
            "6fda1e5ab1fc4d789e31f4b314de8626",
            "d95b6682f44f433facd8feb3d817ffeb",
            "f37fe7c8f32c41b2a48522403077f70f",
            "193c22c8a63f43f495d2e530696368fa",
            "f8aad02c868d46fd963790769b0d77db",
            "bc0b95470a5a4677938fe9000aeaf5c5",
            "3d61fd0bfb674faa9492b62aa7586a57",
            "ac2eb270da4349aea448ff654a23297a",
            "6b116077fab3433383bb602abb2a39be",
            "e51e143f8efe41668cdbeb4247fe400b",
            "49cce6d3007440869ded8071d720ec0e",
            "f7a6c518068b4512b738abd62f4bf286",
            "769733745df94450a3b303bd98fa5421",
            "a3bf8aeaf1024f4893a1a198d0659caf",
            "3f530fb2ae39437687bb3420f969e5e6",
            "f5cf7ef54ec146448edb8959b1ba5b7e",
            "5fdb26716ec340cc9ab636f45c208357",
            "836492f0d8534d0f8dbb959bf9c74524",
            "384c26ff0dce443890f09165daaebd4e",
            "f426d541efc646529bdc326bba0deb8b",
            "317c99bc42e44a16bd93278498b01fe1",
            "ddfcb5a4cf404733aa45b4218e9166d2",
            "73036e0e1f7d4d55b7ff37947d086f32",
            "192a549506d94a4a8150bb9c044593de",
            "a4ba5980fe324350a4f5db599c81d76f",
            "707501ad0a384a82a4bc60c63d6e09d9",
            "0537c4558d984ac993f6700a2be26215",
            "7d946655da984aca8cb9f787dd551c4a",
            "29f315a6000a40ca83d5631e4ca30c26",
            "001f3a03f00e48f7b9c8ca71d5d769e0",
            "1dea0952ff8b4faaa4cc70e95aeeb7b5",
            "defdcb4fe0144ec4bbc982e67e672aef",
            "004fed6acced44be9af50e6948a81a85",
            "3785ee03e03e4fa7ad4e0bbdf8fd3ecb",
            "636dc0cafca544a19e98785383cf8963",
            "ece2199dc4b448648d00b6c82b5fbc2a",
            "c81cf2cd5e3843679c2b6593fd5c0282",
            "b22f373562de402da8a0b2bac5ef4576",
            "c74037343f1d42a4a58acd2670122b14",
            "34b00028eb8845b9a78f69e6c2e63b4c",
            "a878dd6d6390417286f97d3b8889da9e",
            "859d140ee1364e3c888b47626e403e60",
            "4a47a7ef645147658beefbe1f786d1e0",
            "3ef69c7b22e44abb87e8201cc5a11954",
            "83e40a45bae44892be94960dc688b030",
            "d1c426b2c5b7431ebb03215f4ea97b63",
            "f99f00695de54f2aaa58e6eeeeec9996",
            "fb6472f1353142a2b0c648b5e9a8dc2b",
            "ca00c7420ddf4bcfb3e19ff91c66e62f",
            "62946ea6c79c441dbc3aa406913fe33a",
            "557613da18184f04a9f7bf3f76e109c3",
            "65248e0edce543e483d0aa3388eae26d",
            "36154a79e27e49c687012151fc174d78",
            "f908300d5f594dc194f285283f432003",
            "354ef935688546cab9399ace3be21d0b",
            "c962e744f2974513bbaafb37b6d56774",
            "4e6deb74b75f4631848cc838563287d2",
            "87580013ecd547a594d977581f4ee43a",
            "69f06dbf850a4a18a89cb9a8d21dec72",
            "4712b34fe551483cb301f98dc6cd945c",
            "ccddc76920134963bb588491ac4e8fb9",
            "6973a614a9154aa29591a26c46e9e8c1",
            "09c71def5bf7471f83d0f22902c44b75",
            "50883975c93b4767b703d21d9bc3ad98",
            "62b32b28e947469db238bb1f7fbffe0c",
            "12de3b5299134543ae4136ef4270f30c",
            "81d52f327cec45378b8eb6088023d84c",
            "f50c8bed197c49ea99b86daca08bdd4e",
            "50c5cfae85664e3da8f15a5ae2a9a945",
            "b1d6d578276f49a7baaadf9ce01ccd30",
            "b9c6ec5dde73413791e481bb6cea7bf3",
            "33b0502e5d914d8a94e3e0bab35deccc",
            "74da1cb89f644a3290b0160a8d3b7000",
            "bcc63c6d19e54f15a1dcd30d8b1c8c6f",
            "489b254374394be59290237b2f30430c",
            "b53a0783bd44415f9d64db4231c9a6a2",
            "c51ef4a8b5cf4c5293a5e365df98fd94",
            "e1e03d6f981b4679a3466a090c5a8ef0",
            "814f2ba77d84446fa3ddb6f5052813d4",
            "9d21b58b10df451e9759522a2bef2eea",
            "009e3a71f8cf4744ae817cb31fdcc374",
            "11bff0bb5a9b4d9eae42cb3f139ef971",
            "7b52fab9190943d088bc582b81d78684",
            "e57b7868d9244ece82399c60c57f28fd",
            "dddc56bb295049c19f89f2b2deeb1566",
            "fac94a4b8cc941e9a8f549b4b3852ea2",
            "639a166b9d8b4c509107d92df3c0592d",
            "5c48c7a1ed8049bd8e333d1e86145fc9",
            "5c716d015d0f49508ed6ccf808e464df",
            "342e647c06694347ac28383f65c9adc9",
            "2f23ce6d73604b3fa2c0e2a00df60b04",
            "7986d5dfb874444e98da7792c4716601",
            "44bb8ebb12eb4758a4d52832b709ff96",
            "88fb218701354cb49f923e0bbfe55b3f",
            "4436759be31d4bd68e7b05a4e3b55cba",
            "838084f37c374546895083c84b907fd6",
            "4b985e6c4e1945efbbde2f54e5dc1100",
            "398fd25d00ed48049f3f7c6da6a8088b",
            "97db65c152924e8092915992280433f6",
            "acb3f7fc1b764cd4be0d78b8eece60ca",
            "4af6becc1eb84d16bd37437d43c5b706",
            "c2332d3689734498808ee8451c483a6a",
            "20b7e56e7afd48709850d07ad75cbcce",
            "d6a4e3e75d404afaa34e7bde3f4789c5",
            "3a1f09c969bc4be582c60365106d98f5",
            "9b97e830a3ad466bad549a3e91c2251c",
            "fbc3d313ecf641fcb7d9bd7e196ca9f7",
            "767f848943e142489350adeba460bb42",
            "2fc3609eaa2a418f944ae5711f71f6a7",
            "871799db14b3456caa95d803f4cbfa8b",
            "f362f71026ed493e9545165327a38d73",
            "d5d3432dc9914741a31957db3f6e3246",
            "af11595fe6ec40fa980086e986b06deb",
            "dbea73b6510d4869811d203babf1c42c",
            "c6a4f8cc8b0b4395af755e2d39b3ad6e",
            "fa38f2938a644a8dab10c82c1e4044f2",
            "f0ad59629ef94919bc6a764c27449c3c",
            "446927648cf64dd5b562b4359d1251d0",
            "1fa2d78eebc24b5c8bba80de4cc4d7f2",
            "86c2fb2093784cb0923ac0dbe0f1acc5",
            "7aa452fae21040dd99b1cf88cfb67f8c",
            "21016154c6b74ce2b2798d273eed1666",
            "c7997231dfe84872bc44cc2da8287877",
            "278d6acf6c6841e4b9d7b13723635ee4",
            "e038fbcd378c4a178ed5cb8ae03d5cbe",
            "a45a1b6a5195497c85b8ae19c34b592b",
            "b4f4c2e21b124acc82e64dd77bc75694",
            "a9b6b221a53742739b0765f91f9cebaa",
            "4dadbac72d0b4f6b98377728253223fd",
            "ff8806cbc9a94eb9981cd4dca8f8c62d",
            "d42dba8428ce4e6f901f0a1c64ce1f3a",
            "a2ff093c15804ae5bae49899ac30eba0",
            "a1ebc30e595d4d8a8d22dd7a60e54db8",
            "7f3f093960c548428f9938db58197b9f",
            "3dacd1647a8740169658c4be6a59ab72",
            "de0490ad51e74cf8b3ebbff6110db3c9",
            "5f879d03ba714891bf766a52b8d82e0c",
            "22053c755da34bdcacac5d0a43eca074",
            "fb15fbb7674245559958c217d527936c",
            "abcd1b074d50475c96210e2b4733f4bc",
            "728715065a52407c9c05d7a4ab35497e",
            "c606b38aff67451aac9e6863d470dfca",
            "59e794369be34e3980d53162f5e61c33",
            "f71d33c9d4c745db9e4a5c28ecdf7465",
            "c9dc3031097d4dc298a3d8399d5a8317",
            "9a6406279c534b719242921b47f56766",
            "0a00d2b2329b4830ae8897c8f7ba2442",
            "36a4e8f513374a309dc7e5832b5f3806",
            "7d95f9879afb427cbf9c52918eac11cd",
            "f4415234e240455a94b289b246ccade4",
            "6d8d0a44f0b24a38ba1aa871beffbe8c",
            "0a3099ce7d384b529a7cac7fad6c3d63",
            "dd6c15253b064782bbf27d617bf331fe",
            "6deb857b490e4aedbf50a53bb2b88db0",
            "02709fac50044b1abe3dddf2c513a2d1",
            "f1f10eea91414973848e9435e0d2eeda",
            "188c77f06efd4ac6a7f280a785b7349e",
            "d404df20b44141c88b31b23f503b1507",
            "2ab26611df5244ea8153d58c6d0b2f75",
            "090013e2c1214300a86d305720b24ef6",
            "305cf3a1c33a4a42b500e0ac1aad757b",
            "5c8ad35371004e939b1f29974ee70fbd",
            "b9f9c1530456408d9de86de8924aa5b4",
            "9f6532b7990149048d34221424323817",
            "209761fb3c1e462cb581a36cdf1e7c29",
            "70b898efe38e419c873494487d955fca",
            "35c7639a6e7c44cbb0487fbac3924731",
            "2e010be3c5da4ba7878030e7c66afb60",
            "91cc73596c9045a3bbc216dd286cbdd6",
            "175501ed667f4de985419e6d81b7198a",
            "5ac5868da72e402d90819e045765994a",
            "c64d4e4de62045a5b78f12f7bcc696f9",
            "4a84efac09bc437c9f9aaee897b2642e",
            "c060b25e95c246789ddfb524a104f579",
            "953b4881e6594a76afcff8f6b3a8608b",
            "3ed22851b08a4a439ed0d0573fa54401",
            "3a5e815fa5a9401f8cbcfb843024a6cf",
            "16b3f87412e64b0c964d95eb333f3980",
            "2691078ac1ea4ec09d0b1a3923fa7ba0",
            "ab5dd11637e04e79970d17ccc5f8fcec",
            "d14e294110c44f29927c7976ab6915df",
            "423cc752eba94557b45cab75576187fc",
            "8c4569a03c8e4e239c97ddf73c85a197",
            "6d61e3eab78e4b498b5bdb8fc86866f0",
            "626942a8b5784c00a156dd6bb1787a28",
            "57fd70739669474fa9077cef626afdc1",
            "b6dd165f9c634da9a2148bd590980d64",
            "f50a9f077c5e4d7e8173b5f5afea14ab",
            "eb382cca9e5f4c13aff8307e4cc6cd71",
            "bfd47792d06846fea0f8b8ef46a37b1d",
            "f54d76ed5ce443ebb3c385ca12b509e2",
            "5d5135921e68454b85a67969e12f36f6",
            "7aca164709734470bd7c152419044f71",
            "51125248a3c2489f81a3e990a8b3fc8c",
            "c289b0188922491e8ce8f6386f37f452",
            "e6f69ef33ed3444e9b8c8e25bbdfd08f",
            "9b5685d1ce5a431391e12289becb50fa",
            "4ed61d440ffe4f3b9e87141ff51c9506",
            "e69c99204e3f453592ad5729e96bfb45",
            "be8c30eb0abc4606a91ad9311a6c45aa",
            "ab977680dd6443f5b3709176bb0e5616",
            "ddcd9ce87328416684dc4bec78d19e73",
            "3d8eca81cac0419eb454b623bdfa6573",
            "1883e1080cd04790a20533e5717106db",
            "9432373947294ca89a46de25c7f2ffb4",
            "f0af89476c284e8cbed92de7a86cd966",
            "daf25bf55a384deea5ea1f0974bbc9f9",
            "be8766a83f064da987696fe23821b3de",
            "60d495f5195f40f79a5d4291b195d8de",
            "98d80246943e41c79816e9b8b347985c",
            "319f59d483ec41db857e1ce3332274fc",
            "89dd6a272aeb4b82a083c9e3de41d389",
            "2e93e37578da4dabae9ca8a3fac2a704",
            "c1502e33d63a4d7ab6c386ee745b32eb",
            "8af87be55af5460395a6cef36917c58d",
            "5dbb0b02c0b44eec8d2c104951cf41f7",
            "bf9b79a3c4bf43a48a92e3216cbe5e86",
            "3a9fc3e3dab444589fd9a1a080f7aaae",
            "b3fb33bb000c4d898c140fb0dc4b5995",
            "6863cb04757c45be8fa57b80d72c4b54",
            "9038d561c03e48aea2c946e85f81a014",
            "23709e30c27c4b35baa8a77528bd388d",
            "6c8a97055b5e497f9161b946287adf58",
            "415dec555cd14cfea92b110c435fb89c",
            "f72e1e2e63f342eb8f3083b0c13cbf39",
            "8b6a6cec8e7c4e9292411d28c7fa9daa",
            "79037335c6a946ae89cf32444abdd55f",
            "5a2826640d804f538670eff3936eb03b",
            "0ba0300d80f64fd7bef09e6fb61b6714",
            "1ce30a7a04194db0ac59b841169b61e9",
            "f997aa2e7aac4097966ad7361d25380f",
            "fe432906963a4da199e1a7fc5e13143a",
            "bff5d708555a4beea39a723005e53d21",
            "ff4571de62494b4494d2428e90fd78bb",
            "71017438019948edaed1c40b2e4b81e8",
            "f6d1a2063328461f9703c67a74363ed5",
            "77061978bb784c7a882788cf2e7ae331",
            "c0c3808809524f6fba4f650501cdfcf8",
            "774d36e9872a491294e0dd1a8218d430",
            "f34fce0b3a1d4953875b729b03a38e05",
            "a5304335bf2a4da1beb30e72c79a5865",
            "64e4764da760481ea21afd779560446c",
            "24c092fcd8324db88937b0589f6f2db6",
            "ab278725a9b8484a82656b795bfb8781",
            "51033b457feb45ccac45bbf5322525bc",
            "90ad66b824b8409693ecc6174474417f",
            "9a68a68a6b254ac586a820fb37bb73d7",
            "4e6f8c93761148e79d46fbbaed66d448",
            "153f5d990fa84f6e9f582a81d52d8a01",
            "8f1dd99c79494eb58c690a77edd9503a",
            "bdffaf1fab0f48d28ca19374103d44ba",
            "ab64f39b5ac347888c0e28cbcfc008d3",
            "ad8e8a71662e46c2a4ace78a53b680a4",
            "75be58fa916d44748e18bd4ecedbf2a7",
            "0abbc5794144434187ad09eff5287072",
            "e816b88cb76e422ea9801ed5c27a3a31",
            "f9f8dbaf7c25465090c6672b6f6beb56",
            "d854a7f0880946dca8b1b65e6cc3041d",
            "661903bd4ccb4bbc92cab02f0bbb9b23",
            "282c5c5946144dfeb24919b9187563ef",
            "4c6ab0940a8844eea4c02356babb6bd0",
            "5cc5052f6daf46ef86629169cd8b820b",
            "5d69225e63e14135b06f84542a3945a3",
            "100f910bea144f03b13c697bcdaacdad",
            "51919bf0ed5b4ece9a564dc84a8818f3",
            "c986539059164593baaefec143fc3b92",
            "d4e6f0fcd4a341f5a49a366ed2d54608",
            "785943c51b624db48556ddf5a9fe4407",
            "de54083bfd044cb6923138dacdf6089e",
            "8014422f5c8541e4b1a71a46f18712a8",
            "5de58162d94740ef8798a376a8af4eaf",
            "f1599a3b95254b59a29fcd1b2c0648a1",
            "1b475267a2754a3eb9d6101949cde506",
            "bde614fb6fdd4e5f86b39cad33e30b27",
            "9d89789c4bfd468bbec35a6689b87850",
            "cef3f15f0acf4d2894d8ab367f7fc98a",
            "0292ca2eac3a4ade9fee21707ba00be3",
            "491a86f940e44d2dad375c59c61793b1",
            "9b3ed1b7710245a8b3b206aab9b853ef",
            "9868b5f3dbf24c559d258a4ac299539a",
            "94b11e6890324a77899b36396a364c82",
            "617ff41c0d344e70a089f1782c392144",
            "ea9503315e8c4c678df5c0e265fd668d",
            "4d0ad6ea91a940d2a99778d94a6f6200",
            "401d69b86cd649a890120f48ec987f42",
            "757d9d3ad03545c59239031503720146",
            "7ddd8c9d752f44708ecc6e3549b3b352",
            "0a43b720afe0400ca5b7d19efcd1f9d1",
            "e33ccad988d24f66932d386b4801eac9",
            "3977ffd01c5c453ab859446100d5c92f",
            "2a588b88d1df400f846b9bd371ca7803",
            "8a3a0859799e4b40bd00ed2acc075c1d",
            "c62ced585fd54aac9ab7ea6e33d9944e",
            "fbbf5cac4cd44528a7b567b71849e70c",
            "18551becd56a4e3b9edfdab52342850b",
            "510944078eb541b4a1596814eb5bf172",
            "d2c1cfaca9354b3abf1054eab0f9deba",
            "2d1a3ddd4ba8418cb07d5286f07a0c53",
            "ed4e187772da436dba76254a6de4dcbb",
            "e6471cfde0a24ccbae1b22c9bc290187",
            "b910340a95e243dd9a2964bcfa7acfa7",
            "2b4b1d695cdc488d926bad9bbf6bf3d0",
            "7e6dc357808545208ba028f40694019f",
            "c3fd095ae3c74c81b2f71c4e62aacd12",
            "4b84cd52682b4b95ba0ad657a83de80f",
            "317ddcb92ede4f46aca5c9fcc12cf046",
            "7186e863ed6741278ec185ae8f65ea99",
            "af07906cca5548c2969f8aed0eea5285",
            "51a661c7ce0f428ea8c70b41e555a7ea",
            "e1e4b6547c0b4313a8551b749c9420f8",
            "1b8b5a0f45d946d8b4e1df769cd94837",
            "cc237e9b27aa4832b72b62b40ce33ba2",
            "ad5cc31dbe184b52a22931f7601f3ea0",
            "5389bc027de94e4f990a046db432e1df",
            "7a78e0606bd3463d9078d4c3e12c3fd4",
            "7ed570bbfd0841e5bc2e0a3eaaa4c907",
            "204b5d7532fe49199ff27904e33a7079"
          ]
        },
        "id": "uryMok7YE_NV",
        "outputId": "74868b12-953f-4897-a1ad-c5b8d61d43da"
      },
      "source": [
        "# Automated\n",
        "from collections import OrderedDict\n",
        "\n",
        "from transformers.models.auto.tokenization_auto import TOKENIZER_MAPPING_NAMES\n",
        "from transformers.models.auto.modeling_auto import MODEL_MAPPING_NAMES\n",
        "from transformers.models.auto.configuration_auto import CONFIG_MAPPING_NAMES, CONFIG_ARCHIVE_MAP_MAPPING_NAMES\n",
        "\n",
        "from transformers import RobertaTokenizer\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "SE_COMP_MAPPING = OrderedDict()\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "!wget https://huggingface.co/bert-base-uncased/blob/main/vocab.txt\n",
        "\n",
        "# Skip models that will crash the session\n",
        "INCOMPATIBLE_AND_TOO_BIG = [\"blenderbot\"]\n",
        "\n",
        "for model_type, model_name in MODEL_MAPPING_NAMES.items():\n",
        "    print(\"RUNNING: \", model_type, model_name)\n",
        "    if model_type in INCOMPATIBLE_AND_TOO_BIG:\n",
        "        continue\n",
        "    if isinstance(model_name, tuple):\n",
        "        print(f\"Choosing {model_name[0]} from {model_name}\")\n",
        "        model_name = model_name[0]\n",
        "    # Incompatible as SentenceTransformers uses AutoTokenizer to load the model\n",
        "    if (model_type not in TOKENIZER_MAPPING_NAMES) or (model_type not in CONFIG_MAPPING_NAMES):\n",
        "        SE_COMP_MAPPING[model_type] = False\n",
        "        continue\n",
        "\n",
        "    config_name = CONFIG_MAPPING_NAMES[model_type]\n",
        "    config = getattr(__import__(\"transformers\", fromlist=[config_name]), config_name)\n",
        "    model = getattr(__import__(\"transformers\", fromlist=[model_name]), model_name)\n",
        "\n",
        "    tokenizer_name = TOKENIZER_MAPPING_NAMES[model_type]\n",
        "    if isinstance(tokenizer_name, tuple):\n",
        "        tokenizer_name = tokenizer_name[0]\n",
        "    tokenizer = getattr(__import__(\"transformers\", fromlist=[tokenizer_name]), tokenizer_name)\n",
        "    try:\n",
        "        # Load model as small as possible else Memory error e.g. for GPT-J\n",
        "        base_model = model(config(n_layer=1, layers=1, num_layers=1, num_hidden_layers=1, attention_types=[[[\"global\"], 1]], encoder_layers=1, decoder_layers=1))\n",
        "        base_model.save_pretrained(\"./model\")\n",
        "        #base_tok = tokenizer(\"./vocab.txt\")\n",
        "        #ase_tok.save_pretrained(\"./model\")\n",
        "\n",
        "        # RobertaTokenizer will work for most\n",
        "        base_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "        base_tok.save_pretrained(\"./model\")\n",
        "        sen_model = SentenceTransformer(\"./model\")\n",
        "        embeddings = sen_model.encode(sentences)\n",
        "\n",
        "        print(f\"Output for {model_type}: {embeddings.shape}\")\n",
        "        !rm -r ./model\n",
        "        del base_model\n",
        "        del sen_model\n",
        "        SE_COMP_MAPPING[model_type] = True\n",
        "\n",
        "    except Exception as e1:\n",
        "        print(f\"EXCEPTING once due to {e1}\")\n",
        "        # Else try its own tokenizer\n",
        "        try:\n",
        "            !rm ./model/tokenizer_config.json\n",
        "            !rm ./model/special_tokens_map.json\n",
        "            !rm ./model/vocab.json\n",
        "            !rm ./model/merges.txt\n",
        "            !rm ./model/added_tokens.json\n",
        "\n",
        "            # Else try the models tokenizer - but possibly with wrong initialization\n",
        "            base_tok = tokenizer(\"./vocab.txt\")\n",
        "            base_tok.save_pretrained(\"./model\")\n",
        "\n",
        "            sen_model = SentenceTransformer(\"./model\")\n",
        "            embeddings = sen_model.encode(sentences)\n",
        "\n",
        "            print(f\"Output for {model_type}: {embeddings.shape}\")\n",
        "            !rm -r ./model\n",
        "            del base_model\n",
        "            del sen_model\n",
        "            SE_COMP_MAPPING[model_type] = True\n",
        "        \n",
        "        except Exception as e2:\n",
        "            print(f\"EXCEPTING twice due to {e2}\")\n",
        "            # Else try pretrained model\n",
        "            try: \n",
        "                config_archive_name = CONFIG_ARCHIVE_MAP_MAPPING_NAMES[model_type]\n",
        "                config_archive = getattr(__import__(\"transformers\", fromlist=[config_archive_name]), config_archive_name)\n",
        "                base_weight = list(config_archive.keys())[0]\n",
        "                sen_model = SentenceTransformer(base_weight)\n",
        "                embeddings = sen_model.encode(sentences)\n",
        "                print(f\"Output for {model_type}: {embeddings.shape}\")\n",
        "                !rm -r ./model\n",
        "                del base_model\n",
        "                del sen_model\n",
        "                SE_COMP_MAPPING[model_type] = True\n",
        "            except Exception as e3:\n",
        "                print(f\"INCOMPATIBLE {model_type} due to {e1} and {e2} and {e3}\")\n",
        "                SE_COMP_MAPPING[model_type] = False\n",
        "# Mistakes:\n",
        "# gpt_neo is incompatible (incompatible due to the gpt-neo tokenizer not having a padding token)\n",
        "# sentence-transformer asks for the padding token internally; With a RobertaTokenizer like here it would work"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-26 12:38:53--  https://huggingface.co/bert-base-uncased/blob/main/vocab.txt\n",
            "Resolving huggingface.co (huggingface.co)... 3.94.225.255, 34.197.18.55, 2600:1f18:147f:e850:2b5a:d015:5266:6170, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.94.225.255|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6719789 (6.4M) [text/html]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>]   6.41M  22.6MB/s    in 0.3s    \n",
            "\n",
            "2021-10-26 12:38:54 (22.6 MB/s) - ‘vocab.txt’ saved [6719789/6719789]\n",
            "\n",
            "RUNNING:  fnet FNetModel\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "848ed0277d814dab96951d76563d7f8a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66742411db834fb089eb598b5cd43fbf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d3eeeec405e489aa7c4a7a669ffd01e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "912150ea3aad48bcaa98444c7fb65fe5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to forward() got an unexpected keyword argument 'attention_mask'\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260474357328 on /root/.cache/torch/sentence_transformers/google_fnet-base/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260474357328 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11713912474f4c6dac9445f2b70fd230",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/737 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260474357328 on /root/.cache/torch/sentence_transformers/google_fnet-base/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260474357328 released on /root/.cache/torch/sentence_transformers/google_fnet-base/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260517623120 on /root/.cache/torch/sentence_transformers/google_fnet-base/README.md.lock\n",
            "DEBUG:filelock:Lock 140260517623120 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dabd934415d4b098b4d010cde0085f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/12.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260517623120 on /root/.cache/torch/sentence_transformers/google_fnet-base/README.md.lock\n",
            "DEBUG:filelock:Lock 140260517623120 released on /root/.cache/torch/sentence_transformers/google_fnet-base/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260517623120 on /root/.cache/torch/sentence_transformers/google_fnet-base/config.json.lock\n",
            "DEBUG:filelock:Lock 140260517623120 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db2e296f0fe540329351b31ce8c4e018",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/626 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260517623120 on /root/.cache/torch/sentence_transformers/google_fnet-base/config.json.lock\n",
            "DEBUG:filelock:Lock 140260517623120 released on /root/.cache/torch/sentence_transformers/google_fnet-base/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260509991568 on /root/.cache/torch/sentence_transformers/google_fnet-base/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260509991568 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "192908063e91435b87d9d05c4fec07b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/334M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260509991568 on /root/.cache/torch/sentence_transformers/google_fnet-base/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260509991568 released on /root/.cache/torch/sentence_transformers/google_fnet-base/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260501937360 on /root/.cache/torch/sentence_transformers/google_fnet-base/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260501937360 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af844f36413d46fab637c23b9b6deb59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/201 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260501937360 on /root/.cache/torch/sentence_transformers/google_fnet-base/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260501937360 released on /root/.cache/torch/sentence_transformers/google_fnet-base/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260673541904 on /root/.cache/torch/sentence_transformers/google_fnet-base/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260673541904 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/spiece.model.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30a5baf29089421cbc305abc49a1868a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/708k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260673541904 on /root/.cache/torch/sentence_transformers/google_fnet-base/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260673541904 released on /root/.cache/torch/sentence_transformers/google_fnet-base/spiece.model.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260501652624 on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260501652624 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aebe323ebd74be199e6b9a1b0153abd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260501652624 on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260501652624 released on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260517622672 on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260517622672 acquired on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c620abc2940454ba093671820f7c7cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/430 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260517622672 on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260517622672 released on /root/.cache/torch/sentence_transformers/google_fnet-base/tokenizer_config.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/google_fnet-base. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/google_fnet-base were not used when initializing FNetModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing FNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing FNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE fnet due to forward() got an unexpected keyword argument 'attention_mask' and Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  and 'attention_mask'\n",
            "RUNNING:  gptj GPTJModel\n",
            "RUNNING:  layoutlmv2 LayoutLMv2Model\n",
            "EXCEPTING once due to \n",
            "LayoutLMv2Model requires the detectron2 library but it was not found in your environment. Checkout the instructions on the\n",
            "installation page: https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md and follow the ones\n",
            "that match your environment.\n",
            "\n",
            "rm: cannot remove './model/tokenizer_config.json': No such file or directory\n",
            "rm: cannot remove './model/special_tokens_map.json': No such file or directory\n",
            "rm: cannot remove './model/vocab.json': No such file or directory\n",
            "rm: cannot remove './model/merges.txt': No such file or directory\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to You must provide corresponding bounding boxes\n",
            "INCOMPATIBLE layoutlmv2 due to \n",
            "LayoutLMv2Model requires the detectron2 library but it was not found in your environment. Checkout the instructions on the\n",
            "installation page: https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md and follow the ones\n",
            "that match your environment.\n",
            " and You must provide corresponding bounding boxes and 404 Client Error: Not Found for url: https://huggingface.co/api/models/sentence-transformers/layoutlmv2-base-uncased\n",
            "RUNNING:  beit BeitModel\n",
            "RUNNING:  rembert RemBertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for rembert: (2, 1152)\n",
            "RUNNING:  visual_bert VisualBertModel\n",
            "RUNNING:  canine CanineModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for canine: (2, 768)\n",
            "RUNNING:  roformer RoFormerModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for roformer: (2, 768)\n",
            "RUNNING:  clip CLIPModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to 'CLIPConfig' object has no attribute 'hidden_size'\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to __init__() missing 1 required positional argument: 'merges_file'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260452158160 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260452158160 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2783749a68e4ff3bdc5181e37d2ff59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452158160 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260452158160 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260489376720 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/README.md.lock\n",
            "DEBUG:filelock:Lock 140260489376720 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1883b82e247d49d29e4b744a0837bf40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.03k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260489376720 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/README.md.lock\n",
            "DEBUG:filelock:Lock 140260489376720 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260466677328 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/config.json.lock\n",
            "DEBUG:filelock:Lock 140260466677328 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28dad7df3cea4b9682c943e3d88013f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.98k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260466677328 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/config.json.lock\n",
            "DEBUG:filelock:Lock 140260466677328 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260474265104 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/merges.txt.lock\n",
            "DEBUG:filelock:Lock 140260474265104 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/merges.txt.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75f8f837cd954be0b6ce2ad6e14993ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260474265104 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/merges.txt.lock\n",
            "DEBUG:filelock:Lock 140260474265104 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/merges.txt.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260509991504 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260509991504 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/preprocessor_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49d20422564543809ac7bd3068633996",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260509991504 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260509991504 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452184656 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260452184656 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "346c5b6a2b854133be24948b7f3fa1b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452184656 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260452184656 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476560528 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260476560528 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e65271f0c57644a19305e841df7be60d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476560528 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260476560528 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260489378192 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260489378192 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2be000cbe2844e4cbb91ad03fb9f616c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.49M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260489378192 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260489378192 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476560528 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260476560528 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3443788fc1bc46c0b6203458fb59029e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/568 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476560528 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260476560528 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260470577296 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260470577296 acquired on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/vocab.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b95969e9bf2435f8dacec274382bc80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/862k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260470577296 on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260470577296 released on /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32/vocab.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/openai_clip-vit-base-patch32. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE clip due to 'CLIPConfig' object has no attribute 'hidden_size' and __init__() missing 1 required positional argument: 'merges_file' and 'CLIPConfig' object has no attribute 'hidden_size'\n",
            "RUNNING:  bigbird_pegasus BigBirdPegasusModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 7 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3.Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for bigbird_pegasus: (2, 1024)\n",
            "RUNNING:  deit DeiTModel\n",
            "RUNNING:  luke LukeModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for luke: (2, 768)\n",
            "RUNNING:  detr DetrModel\n",
            "RUNNING:  gpt_neo GPTNeoModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for gpt_neo: (2, 2048)\n",
            "RUNNING:  big_bird BigBirdModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Attention type 'block_sparse' is not possible if sequence_length: 7 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3.Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for big_bird: (2, 768)\n",
            "RUNNING:  speech_to_text Speech2TextModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to forward() got an unexpected keyword argument 'input_ids'\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to __init__() missing 1 required positional argument: 'spm_file'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260458724560 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260458724560 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cca395f745c74f589c95540a5c9b5971",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458724560 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260458724560 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260493247504 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/README.md.lock\n",
            "DEBUG:filelock:Lock 140260493247504 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0e509cec1a04720af77e6217a6af5f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.63k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260493247504 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/README.md.lock\n",
            "DEBUG:filelock:Lock 140260493247504 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260456788112 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/config.json.lock\n",
            "DEBUG:filelock:Lock 140260456788112 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1839428a70a847b8ad48292b7b6b7c4c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260456788112 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/config.json.lock\n",
            "DEBUG:filelock:Lock 140260456788112 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260455308368 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260455308368 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/preprocessor_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8891de2e73c947bf876ba12d18f9854f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260455308368 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260455308368 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458626576 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260458626576 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5062b92603c4b63a568b04bccf6e573",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/118M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458626576 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260458626576 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260453097808 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/sentencepiece.bpe.model.lock\n",
            "DEBUG:filelock:Lock 140260453097808 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/sentencepiece.bpe.model.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f896b10c86b244ed905a9ad4f8fe5fb7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/417k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260453097808 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/sentencepiece.bpe.model.lock\n",
            "DEBUG:filelock:Lock 140260453097808 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/sentencepiece.bpe.model.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452067216 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260452067216 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "088db30a9aff466080f2a48171666ed3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452067216 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260452067216 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260455308368 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260455308368 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5243d1b72eed4cab9ebee5b5c7224413",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260455308368 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260455308368 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458767696 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260458767696 acquired on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/vocab.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccfc26fc6b1b4afa8ed8a5b61b938a95",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/235k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458767696 on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260458767696 released on /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr/vocab.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr were not used when initializing Speech2TextModel: ['lm_head.weight']\n",
            "- This IS expected if you are initializing Speech2TextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Speech2TextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Speech2TextModel were not initialized from the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_s2t-small-librispeech-asr and are newly initialized: ['model.encoder.embed_positions.weights', 'model.decoder.embed_positions.weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE speech_to_text due to forward() got an unexpected keyword argument 'input_ids' and __init__() missing 1 required positional argument: 'spm_file' and forward() got an unexpected keyword argument 'input_ids'\n",
            "RUNNING:  vit ViTModel\n",
            "RUNNING:  wav2vec2 Wav2Vec2Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to forward() got an unexpected keyword argument 'input_ids'\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260458625168 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260458625168 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c75de428bb354f59a2eb732347ddddd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/736 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458625168 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260458625168 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260466930832 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/README.md.lock\n",
            "DEBUG:filelock:Lock 140260466930832 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5642043c7744c6e941dad84607624f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.12k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260466930832 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/README.md.lock\n",
            "DEBUG:filelock:Lock 140260466930832 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458625168 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/config.json.lock\n",
            "DEBUG:filelock:Lock 140260458625168 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4404c93f546241f58eee1ca45d636981",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458625168 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/config.json.lock\n",
            "DEBUG:filelock:Lock 140260458625168 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260457061712 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/feature_extractor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260457061712 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/feature_extractor_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5089de68f6be4a76875dffc60ca71e4f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/158 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260457061712 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/feature_extractor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260457061712 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/feature_extractor_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476786320 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260476786320 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/preprocessor_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25d8f26dbc3a44b3827287e6e4a71d60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476786320 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260476786320 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260456832336 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260456832336 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b9cd5d00ae24dc0a063643cc455f725",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/378M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260456832336 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260456832336 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260485089552 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260485089552 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8a6875e55bb41d5a7f36ea8b0215209",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260485089552 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260485089552 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260466930832 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260466930832 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "368f6d79d9b8477dba23abca6b3eb07a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260466930832 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260466930832 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452187280 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260452187280 acquired on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/vocab.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd7fece32343437fa57cfca0489d89cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452187280 on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260452187280 released on /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h/vocab.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.bias', 'lm_head.weight']\n",
            "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE wav2vec2 due to forward() got an unexpected keyword argument 'input_ids' and Expecting value: line 1 column 1 (char 0) and forward() got an unexpected keyword argument 'input_ids'\n",
            "RUNNING:  hubert HubertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to forward() got an unexpected keyword argument 'input_ids'\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260476786320 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260476786320 acquired on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce0f50d2565749ed9fd7ec8ab352129e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476786320 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260476786320 released on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260472828560 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/README.md.lock\n",
            "DEBUG:filelock:Lock 140260472828560 acquired on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "def85cbaed07459a9edc9009a7a103c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260472828560 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/README.md.lock\n",
            "DEBUG:filelock:Lock 140260472828560 released on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260486652240 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/config.json.lock\n",
            "DEBUG:filelock:Lock 140260486652240 acquired on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8df3b2c36d134e16bbe118d73473c84e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260486652240 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/config.json.lock\n",
            "DEBUG:filelock:Lock 140260486652240 released on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452221136 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260452221136 acquired on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/preprocessor_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4b0dfc99f7640d4be0e184ad5f94216",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/213 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452221136 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Lock 140260452221136 released on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/preprocessor_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260485090576 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260485090576 acquired on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99e9bbea1ad3426db0a440b6b8f12ffc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/378M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260485090576 on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260485090576 released on /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960/pytorch_model.bin.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE hubert due to forward() got an unexpected keyword argument 'input_ids' and Expecting value: line 1 column 1 (char 0) and Can't load tokenizer for '/root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960'. Make sure that:\n",
            "\n",
            "- '/root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960' is a correct model identifier listed on 'https://huggingface.co/models'\n",
            "\n",
            "- or '/root/.cache/torch/sentence_transformers/facebook_hubert-base-ls960' is the correct path to a directory containing relevant tokenizer files\n",
            "\n",
            "\n",
            "RUNNING:  m2m_100 M2M100Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to __init__() missing 1 required positional argument: 'spm_file'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260458745360 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260458745360 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a46cf02a15ef4a7884e413fd85947886",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458745360 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260458745360 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458745360 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/README.md.lock\n",
            "DEBUG:filelock:Lock 140260458745360 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3566112627542b28a5afeaaf62f5acd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.10k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458745360 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/README.md.lock\n",
            "DEBUG:filelock:Lock 140260458745360 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476532432 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/config.json.lock\n",
            "DEBUG:filelock:Lock 140260476532432 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b91bcdeacefd4dfbb239c7ac7dbcaaee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/908 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476532432 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/config.json.lock\n",
            "DEBUG:filelock:Lock 140260476532432 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458745360 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260458745360 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0deee76b00c4f788b6cc32d7da6d9f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458745360 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260458745360 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260470790032 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/sentencepiece.bpe.model.lock\n",
            "DEBUG:filelock:Lock 140260470790032 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/sentencepiece.bpe.model.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "180dbf33401b43f78f5f4467a393355d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260470790032 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/sentencepiece.bpe.model.lock\n",
            "DEBUG:filelock:Lock 140260470790032 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/sentencepiece.bpe.model.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260454080336 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260454080336 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e133f73f34b246b0b7481a236e13b8eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260454080336 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260454080336 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260466657680 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260466657680 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24fb9ec9ea5945e68c109bee6dce0676",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/272 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260466657680 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260466657680 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260486653328 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260486653328 acquired on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/vocab.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a01643f7cd834daf8efa4001644ba49f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.71M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260486653328 on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260486653328 released on /root/.cache/torch/sentence_transformers/facebook_m2m100_418M/vocab.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/facebook_m2m100_418M. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_m2m100_418M were not used when initializing M2M100Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing M2M100Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing M2M100Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of M2M100Model were not initialized from the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_m2m100_418M and are newly initialized: ['model.encoder.embed_positions.weights', 'model.decoder.embed_positions.weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE m2m_100 due to You have to specify either decoder_input_ids or decoder_inputs_embeds and __init__() missing 1 required positional argument: 'spm_file' and You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "RUNNING:  convbert ConvBertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for convbert: (2, 768)\n",
            "RUNNING:  led LEDModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for led: (2, 1024)\n",
            "RUNNING:  blenderbot-small BlenderbotSmallModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to __init__() missing 1 required positional argument: 'merges_file'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260490607888 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260490607888 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33cdf03d7d514435ae855aad4250f67a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260490607888 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260490607888 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260470409680 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/README.md.lock\n",
            "DEBUG:filelock:Lock 140260470409680 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa36c0d18d0e49ab96baa6c7121f528b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260470409680 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/README.md.lock\n",
            "DEBUG:filelock:Lock 140260470409680 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260459356112 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/config.json.lock\n",
            "DEBUG:filelock:Lock 140260459356112 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "228f296e942144aba158fb9e47c9e700",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260459356112 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/config.json.lock\n",
            "DEBUG:filelock:Lock 140260459356112 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260490607696 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/merges.txt.lock\n",
            "DEBUG:filelock:Lock 140260490607696 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/merges.txt.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b525038488854cd287692a334874c316",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260490607696 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/merges.txt.lock\n",
            "DEBUG:filelock:Lock 140260490607696 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/merges.txt.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260459354128 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260459354128 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20a73093de1e4a6bad4fe58627120702",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/350M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260459354128 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260459354128 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260478425552 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260478425552 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c97aa1a8a87441a4b38d35059413ebe1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260478425552 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260478425552 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260455307344 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260455307344 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d58e5ab01d3945e1a203763355d8f212",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/205 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260455307344 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260455307344 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452169488 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260452169488 acquired on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/vocab.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f631bf5a0b7143419010b68e7d6aeb92",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/964k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452169488 on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260452169488 released on /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M/vocab.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_blenderbot_small-90M were not used when initializing BlenderbotSmallModel: ['lm_head.weight', 'final_logits_bias']\n",
            "- This IS expected if you are initializing BlenderbotSmallModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BlenderbotSmallModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE blenderbot-small due to You have to specify either decoder_input_ids or decoder_inputs_embeds and __init__() missing 1 required positional argument: 'merges_file' and You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "RUNNING:  retribert RetriBertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to forward() got an unexpected keyword argument 'input_ids'\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Can't set num_hidden_layers with value 1 for MT5Config {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layers\": 1,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"n_layer\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.11.3\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to WordPiece error: Missing [UNK] token from the vocabulary\n",
            "INCOMPATIBLE retribert due to forward() got an unexpected keyword argument 'input_ids' and WordPiece error: Missing [UNK] token from the vocabulary and 404 Client Error: Not Found for url: https://huggingface.co/api/models/sentence-transformers/retribert-base-uncased\n",
            "RUNNING:  mt5 MT5Model\n",
            "EXCEPTING once due to can't set attribute\n",
            "rm: cannot remove './model/vocab.json': No such file or directory\n",
            "rm: cannot remove './model/merges.txt': No such file or directory\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \n",
            "INCOMPATIBLE mt5 due to can't set attribute and Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  and 'mt5'\n",
            "RUNNING:  t5 T5Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260480786640 on /root/.cache/torch/sentence_transformers/t5-small/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260480786640 acquired on /root/.cache/torch/sentence_transformers/t5-small/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1913d6bd39fb4f5c95370ffba7ea4876",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260480786640 on /root/.cache/torch/sentence_transformers/t5-small/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260480786640 released on /root/.cache/torch/sentence_transformers/t5-small/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260469234768 on /root/.cache/torch/sentence_transformers/t5-small/README.md.lock\n",
            "DEBUG:filelock:Lock 140260469234768 acquired on /root/.cache/torch/sentence_transformers/t5-small/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e6084867b364be697aa2dbc7f9f3909",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260469234768 on /root/.cache/torch/sentence_transformers/t5-small/README.md.lock\n",
            "DEBUG:filelock:Lock 140260469234768 released on /root/.cache/torch/sentence_transformers/t5-small/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260490037392 on /root/.cache/torch/sentence_transformers/t5-small/config.json.lock\n",
            "DEBUG:filelock:Lock 140260490037392 acquired on /root/.cache/torch/sentence_transformers/t5-small/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "693b0cc2f36646ea895f5e78877907be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260490037392 on /root/.cache/torch/sentence_transformers/t5-small/config.json.lock\n",
            "DEBUG:filelock:Lock 140260490037392 released on /root/.cache/torch/sentence_transformers/t5-small/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476727632 on /root/.cache/torch/sentence_transformers/t5-small/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260476727632 acquired on /root/.cache/torch/sentence_transformers/t5-small/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "033fca4857434f17ab6ab304a583e41f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476727632 on /root/.cache/torch/sentence_transformers/t5-small/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260476727632 released on /root/.cache/torch/sentence_transformers/t5-small/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476765072 on /root/.cache/torch/sentence_transformers/t5-small/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260476765072 acquired on /root/.cache/torch/sentence_transformers/t5-small/spiece.model.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85af8dd9a36143a08df1404c89248b6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476765072 on /root/.cache/torch/sentence_transformers/t5-small/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260476765072 released on /root/.cache/torch/sentence_transformers/t5-small/spiece.model.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260454080272 on /root/.cache/torch/sentence_transformers/t5-small/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260454080272 acquired on /root/.cache/torch/sentence_transformers/t5-small/tokenizer.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "400f8025fb1c44c48a241f7e338ded3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260454080272 on /root/.cache/torch/sentence_transformers/t5-small/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260454080272 released on /root/.cache/torch/sentence_transformers/t5-small/tokenizer.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/t5-small. Creating a new one with MEAN pooling.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE t5 due to You have to specify either decoder_input_ids or decoder_inputs_embeds and Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  and You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "RUNNING:  pegasus PegasusModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260477552912 on /root/.cache/torch/sentence_transformers/google_pegasus-large/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260477552912 acquired on /root/.cache/torch/sentence_transformers/google_pegasus-large/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6d39f8dfeda4adfb3df18f36ebad298",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260477552912 on /root/.cache/torch/sentence_transformers/google_pegasus-large/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260477552912 released on /root/.cache/torch/sentence_transformers/google_pegasus-large/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452328016 on /root/.cache/torch/sentence_transformers/google_pegasus-large/README.md.lock\n",
            "DEBUG:filelock:Lock 140260452328016 acquired on /root/.cache/torch/sentence_transformers/google_pegasus-large/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4508bb448e994946b3dec39a933bcadb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.33k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452328016 on /root/.cache/torch/sentence_transformers/google_pegasus-large/README.md.lock\n",
            "DEBUG:filelock:Lock 140260452328016 released on /root/.cache/torch/sentence_transformers/google_pegasus-large/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458183696 on /root/.cache/torch/sentence_transformers/google_pegasus-large/config.json.lock\n",
            "DEBUG:filelock:Lock 140260458183696 acquired on /root/.cache/torch/sentence_transformers/google_pegasus-large/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4a5832a306c4c27a6e16ee5b71ce517",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.09k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458183696 on /root/.cache/torch/sentence_transformers/google_pegasus-large/config.json.lock\n",
            "DEBUG:filelock:Lock 140260458183696 released on /root/.cache/torch/sentence_transformers/google_pegasus-large/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260477552528 on /root/.cache/torch/sentence_transformers/google_pegasus-large/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260477552528 acquired on /root/.cache/torch/sentence_transformers/google_pegasus-large/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b66b03028dce4d779be2c53d243fb712",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260477552528 on /root/.cache/torch/sentence_transformers/google_pegasus-large/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260477552528 released on /root/.cache/torch/sentence_transformers/google_pegasus-large/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260469626576 on /root/.cache/torch/sentence_transformers/google_pegasus-large/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260469626576 acquired on /root/.cache/torch/sentence_transformers/google_pegasus-large/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2597401ed501484eaf204525058e908b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260469626576 on /root/.cache/torch/sentence_transformers/google_pegasus-large/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260469626576 released on /root/.cache/torch/sentence_transformers/google_pegasus-large/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260469627024 on /root/.cache/torch/sentence_transformers/google_pegasus-large/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260469627024 acquired on /root/.cache/torch/sentence_transformers/google_pegasus-large/spiece.model.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c3d5e18ded54ffcb86f18411395c820",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260469627024 on /root/.cache/torch/sentence_transformers/google_pegasus-large/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260469627024 released on /root/.cache/torch/sentence_transformers/google_pegasus-large/spiece.model.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260469627024 on /root/.cache/torch/sentence_transformers/google_pegasus-large/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260469627024 acquired on /root/.cache/torch/sentence_transformers/google_pegasus-large/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4077ef04e8c429a9ffd61b7b9b4f3c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260469627024 on /root/.cache/torch/sentence_transformers/google_pegasus-large/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260469627024 released on /root/.cache/torch/sentence_transformers/google_pegasus-large/tokenizer_config.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/google_pegasus-large. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/google_pegasus-large were not used when initializing PegasusModel: ['final_logits_bias']\n",
            "- This IS expected if you are initializing PegasusModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing PegasusModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of PegasusModel were not initialized from the model checkpoint at /root/.cache/torch/sentence_transformers/google_pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE pegasus due to You have to specify either decoder_input_ids or decoder_inputs_embeds and Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  and You have to specify either decoder_input_ids or decoder_inputs_embeds\n",
            "RUNNING:  marian MarianModel\n",
            "EXCEPTING once due to Padding_idx must be within num_embeddings\n",
            "rm: cannot remove './model/tokenizer_config.json': No such file or directory\n",
            "rm: cannot remove './model/special_tokens_map.json': No such file or directory\n",
            "rm: cannot remove './model/vocab.json': No such file or directory\n",
            "rm: cannot remove './model/merges.txt': No such file or directory\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to __init__() missing 2 required positional arguments: 'source_spm' and 'target_spm'\n",
            "INCOMPATIBLE marian due to Padding_idx must be within num_embeddings and __init__() missing 2 required positional arguments: 'source_spm' and 'target_spm' and 'marian'\n",
            "RUNNING:  mbart MBartModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for mbart: (2, 1024)\n",
            "RUNNING:  blenderbot BlenderbotModel\n",
            "RUNNING:  distilbert DistilBertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for distilbert: (2, 768)\n",
            "RUNNING:  albert AlbertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for albert: (2, 4096)\n",
            "RUNNING:  camembert CamembertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for camembert: (2, 768)\n",
            "RUNNING:  xlm-roberta XLMRobertaModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for xlm-roberta: (2, 768)\n",
            "RUNNING:  bart BartModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for bart: (2, 1024)\n",
            "RUNNING:  longformer LongformerModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for longformer: (2, 768)\n",
            "RUNNING:  roberta RobertaModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for roberta: (2, 768)\n",
            "RUNNING:  layoutlm LayoutLMModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for layoutlm: (2, 768)\n",
            "RUNNING:  squeezebert SqueezeBertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for squeezebert: (2, 768)\n",
            "RUNNING:  bert BertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for bert: (2, 768)\n",
            "RUNNING:  openai-gpt OpenAIGPTModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for openai-gpt: (2, 768)\n",
            "RUNNING:  gpt2 GPT2Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for gpt2: (2, 768)\n",
            "RUNNING:  megatron-bert MegatronBertModel\n",
            "RUNNING:  mobilebert MobileBertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for mobilebert: (2, 512)\n",
            "RUNNING:  transfo-xl TransfoXLModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to can't convert negative int to unsigned\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to 'TransfoXLTokenizer' object has no attribute 'sym2idx'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260475941904 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260475941904 acquired on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ea6842eb2224bf18dc651a7358d8fe0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260475941904 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260475941904 released on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260480748944 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/config.json.lock\n",
            "DEBUG:filelock:Lock 140260480748944 acquired on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f32feb3abf134b7a872ed01de8677e35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/856 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260480748944 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/config.json.lock\n",
            "DEBUG:filelock:Lock 140260480748944 released on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260475942160 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/corpus.bin.lock\n",
            "DEBUG:filelock:Lock 140260475942160 acquired on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/corpus.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "499b0a492fb346ff8d961b90410a8c8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/860M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260475942160 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/corpus.bin.lock\n",
            "DEBUG:filelock:Lock 140260475942160 released on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/corpus.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260435777040 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260435777040 acquired on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dc8c68f34824571883b5db1315eb750",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260435777040 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260435777040 released on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260486653520 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.bin.lock\n",
            "DEBUG:filelock:Lock 140260486653520 acquired on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcd2fe52772344a3a0e7b7660e7f6ed1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.14M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260486653520 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.bin.lock\n",
            "DEBUG:filelock:Lock 140260486653520 released on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260447988048 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260447988048 acquired on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bc0a178501046c4bbdf1d0482608d69",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.25M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260447988048 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.json.lock\n",
            "DEBUG:filelock:Lock 140260447988048 released on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260475941072 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.pkl.lock\n",
            "DEBUG:filelock:Lock 140260475941072 acquired on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.pkl.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eed2a06e9004126a77a0f1e39f42831",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.14M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260475941072 on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.pkl.lock\n",
            "DEBUG:filelock:Lock 140260475941072 released on /root/.cache/torch/sentence_transformers/transfo-xl-wt103/vocab.pkl.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/transfo-xl-wt103. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/transfo-xl-wt103 were not used when initializing TransfoXLModel: ['crit.out_layers.2.bias', 'crit.out_projs.1', 'crit.cluster_weight', 'crit.out_layers.1.weight', 'crit.out_layers.0.bias', 'crit.out_layers.2.weight', 'crit.out_layers.3.weight', 'crit.out_projs.0', 'crit.out_projs.2', 'crit.out_projs.3', 'crit.out_layers.0.weight', 'crit.cluster_bias', 'crit.out_layers.3.bias', 'crit.out_layers.1.bias']\n",
            "- This IS expected if you are initializing TransfoXLModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TransfoXLModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE transfo-xl due to can't convert negative int to unsigned and 'TransfoXLTokenizer' object has no attribute 'sym2idx' and Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.\n",
            "RUNNING:  xlnet XLNetModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to can't convert negative int to unsigned\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260426914832 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260426914832 acquired on /root/.cache/torch/sentence_transformers/xlnet-base-cased/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "642d635e7d184af286e657d5aa2c1cc6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260426914832 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260426914832 released on /root/.cache/torch/sentence_transformers/xlnet-base-cased/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458625232 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/README.md.lock\n",
            "DEBUG:filelock:Lock 140260458625232 acquired on /root/.cache/torch/sentence_transformers/xlnet-base-cased/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edb016562e844882b9870eddc2a3bca4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.70k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458625232 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/README.md.lock\n",
            "DEBUG:filelock:Lock 140260458625232 released on /root/.cache/torch/sentence_transformers/xlnet-base-cased/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260484517328 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260484517328 acquired on /root/.cache/torch/sentence_transformers/xlnet-base-cased/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "762a4ac608724534be34b547c940e3b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260484517328 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260484517328 released on /root/.cache/torch/sentence_transformers/xlnet-base-cased/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260484517328 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260484517328 acquired on /root/.cache/torch/sentence_transformers/xlnet-base-cased/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "036d865ef6b94898aab92494c55111e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/467M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260484517328 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260484517328 released on /root/.cache/torch/sentence_transformers/xlnet-base-cased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476730128 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260476730128 acquired on /root/.cache/torch/sentence_transformers/xlnet-base-cased/spiece.model.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba09b8e675c6432d906d22dd5d604acf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476730128 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/spiece.model.lock\n",
            "DEBUG:filelock:Lock 140260476730128 released on /root/.cache/torch/sentence_transformers/xlnet-base-cased/spiece.model.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260466622928 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260466622928 acquired on /root/.cache/torch/sentence_transformers/xlnet-base-cased/tokenizer.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "228044211a8d4fc9932f8cf3b373947e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260466622928 on /root/.cache/torch/sentence_transformers/xlnet-base-cased/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260466622928 released on /root/.cache/torch/sentence_transformers/xlnet-base-cased/tokenizer.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/xlnet-base-cased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE xlnet due to can't convert negative int to unsigned and Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  and can't convert negative int to unsigned\n",
            "RUNNING:  flaubert FlaubertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for flaubert: (2, 2048)\n",
            "RUNNING:  fsmt FSMTModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for fsmt: (2, 42024)\n",
            "RUNNING:  xlm XLMModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for xlm: (2, 2048)\n",
            "RUNNING:  ctrl CTRLModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for ctrl: (2, 1280)\n",
            "RUNNING:  electra ElectraModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for electra: (2, 256)\n",
            "RUNNING:  reformer ReformerModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to index out of range in self\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \n",
            "INCOMPATIBLE reformer due to index out of range in self and Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  and 'reformer'\n",
            "RUNNING:  funnel ('FunnelModel', 'FunnelBaseModel')\n",
            "Choosing FunnelModel from ('FunnelModel', 'FunnelBaseModel')\n",
            "EXCEPTING once due to This model does not support the setting of `num_hidden_layers`. Please set `block_sizes`.\n",
            "rm: cannot remove './model/tokenizer_config.json': No such file or directory\n",
            "rm: cannot remove './model/special_tokens_map.json': No such file or directory\n",
            "rm: cannot remove './model/vocab.json': No such file or directory\n",
            "rm: cannot remove './model/merges.txt': No such file or directory\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to WordPiece error: Missing [UNK] token from the vocabulary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260453099664 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260453099664 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eafbf4215d384bfe9ea574a1a3be2066",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260453099664 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260453099664 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260463304848 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/README.md.lock\n",
            "DEBUG:filelock:Lock 140260463304848 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "927c2f46146e46e28b4a3a30c9380b1a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.86k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260463304848 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/README.md.lock\n",
            "DEBUG:filelock:Lock 140260463304848 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260485478736 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/config.json.lock\n",
            "DEBUG:filelock:Lock 140260485478736 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b70c77f6f3e04a3ca97a677ddbcb8570",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/700 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260485478736 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/config.json.lock\n",
            "DEBUG:filelock:Lock 140260485478736 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260454079312 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260454079312 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ee17cdf68cc42359f01f0ca2bcea543",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/524M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260454079312 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260454079312 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260454079312 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260454079312 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cb6914186844b3982a61b1974913505",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/153 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260454079312 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260454079312 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260463304848 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260463304848 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "033d6b75eb094ce2aa5bf9a46b8b5a11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260463304848 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260463304848 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260494621136 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260494621136 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6264a0a6781449f3a27c07bcb9811043",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/153 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260494621136 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260494621136 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260463304848 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260463304848 acquired on /root/.cache/torch/sentence_transformers/funnel-transformer_small/vocab.txt.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be66368240ad428aaea557030784cd45",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/231k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260463304848 on /root/.cache/torch/sentence_transformers/funnel-transformer_small/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260463304848 released on /root/.cache/torch/sentence_transformers/funnel-transformer_small/vocab.txt.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/funnel-transformer_small. Creating a new one with MEAN pooling.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for funnel: (2, 768)\n",
            "RUNNING:  lxmert LxmertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to `visual_feats` cannot be `None`\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to WordPiece error: Missing [UNK] token from the vocabulary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260482491856 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260482491856 acquired on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59c54caf78684e3b8d07e83ae8d97a66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260482491856 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260482491856 released on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260457351696 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260457351696 acquired on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c45978514c64ddb881d56763459a442",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260457351696 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260457351696 released on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260485479056 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260485479056 acquired on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bea40a17b91943a8b281b506df07ab39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.01G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260485479056 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260485479056 released on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260457351696 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260457351696 acquired on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d889abbdde02484dbf7b62a934459d50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260457351696 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260457351696 released on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260477698128 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260477698128 acquired on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89c1c0267925466697e347955e497379",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260477698128 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260477698128 released on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260459535440 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260459535440 acquired on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "925a5fb74f40400fb7461cfaa87102f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/153 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260459535440 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260459535440 released on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260476359248 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260476359248 acquired on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/vocab.txt.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b5f56b01abc4107865ac2fc5c3ef54e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260476359248 on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260476359248 released on /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased/vocab.txt.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/unc-nlp_lxmert-base-uncased were not used when initializing LxmertModel: ['cls.predictions.transform.LayerNorm.bias', 'obj_predict_head.decoder_dict.obj.weight', 'obj_predict_head.transform.dense.weight', 'obj_predict_head.transform.LayerNorm.weight', 'answer_head.logit_fc.3.weight', 'obj_predict_head.decoder_dict.feat.bias', 'answer_head.logit_fc.3.bias', 'answer_head.logit_fc.2.bias', 'answer_head.logit_fc.2.weight', 'cls.predictions.transform.dense.weight', 'obj_predict_head.decoder_dict.feat.weight', 'obj_predict_head.decoder_dict.obj.bias', 'obj_predict_head.decoder_dict.attr.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'answer_head.logit_fc.0.bias', 'cls.predictions.transform.dense.bias', 'obj_predict_head.decoder_dict.attr.weight', 'obj_predict_head.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'obj_predict_head.transform.dense.bias', 'answer_head.logit_fc.0.weight']\n",
            "- This IS expected if you are initializing LxmertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LxmertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE lxmert due to `visual_feats` cannot be `None` and WordPiece error: Missing [UNK] token from the vocabulary and `visual_feats` cannot be `None`\n",
            "RUNNING:  bert-generation BertGenerationEncoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for bert-generation: (2, 1024)\n",
            "RUNNING:  deberta DebertaModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for deberta: (2, 768)\n",
            "RUNNING:  deberta-v2 DebertaV2Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for deberta-v2: (2, 1536)\n",
            "RUNNING:  dpr DPRQuestionEncoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING once due to expand(torch.LongTensor{[2, 7, 1]}, size=[2, 768]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to WordPiece error: Missing [UNK] token from the vocabulary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260469873616 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.DS_Store.lock\n",
            "DEBUG:filelock:Lock 140260469873616 acquired on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.DS_Store.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e51e143f8efe41668cdbeb4247fe400b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/6.15k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260469873616 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.DS_Store.lock\n",
            "DEBUG:filelock:Lock 140260469873616 released on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.DS_Store.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260477921680 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260477921680 acquired on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "317c99bc42e44a16bd93278498b01fe1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260477921680 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260477921680 released on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260457003024 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/config.json.lock\n",
            "DEBUG:filelock:Lock 140260457003024 acquired on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "defdcb4fe0144ec4bbc982e67e672aef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/492 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260457003024 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/config.json.lock\n",
            "DEBUG:filelock:Lock 140260457003024 released on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260477921936 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260477921936 acquired on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a47a7ef645147658beefbe1f786d1e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260477921936 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260477921936 released on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260435779344 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260435779344 acquired on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f908300d5f594dc194f285283f432003",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260435779344 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer.json.lock\n",
            "DEBUG:filelock:Lock 140260435779344 released on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260501652816 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260501652816 acquired on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62b32b28e947469db238bb1f7fbffe0c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260501652816 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260501652816 released on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260501652816 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260501652816 acquired on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/vocab.txt.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b53a0783bd44415f9d64db4231c9a6a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260501652816 on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260501652816 released on /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base/vocab.txt.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['ctx_encoder.bert_model.encoder.layer.10.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.6.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.11.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.5.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.9.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.0.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.intermediate.dense.bias', 'ctx_encoder.bert_model.embeddings.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.11.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.output.LayerNorm.weight', 'ctx_encoder.bert_model.embeddings.token_type_embeddings.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.8.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.9.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.1.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.0.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.4.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.9.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.1.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.4.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.9.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.3.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.10.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.3.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.intermediate.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.encoder.layer.8.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.8.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.3.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.7.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.7.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.0.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.4.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.0.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.8.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.10.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.2.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.dense.bias', 'ctx_encoder.bert_model.embeddings.word_embeddings.weight', 'ctx_encoder.bert_model.embeddings.position_embeddings.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.9.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.4.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.4.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.query.bias', 'ctx_encoder.bert_model.embeddings.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.1.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.7.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.7.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.intermediate.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.8.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.5.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.1.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.5.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.11.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.2.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.output.dense.weight']\n",
            "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DPRQuestionEncoder were not initialized from the model checkpoint at /root/.cache/torch/sentence_transformers/facebook_dpr-ctx_encoder-single-nq-base and are newly initialized: ['bert_model.encoder.layer.10.attention.self.value.bias', 'bert_model.encoder.layer.8.output.LayerNorm.weight', 'bert_model.encoder.layer.8.attention.self.value.weight', 'bert_model.encoder.layer.7.output.LayerNorm.bias', 'bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.intermediate.dense.weight', 'bert_model.encoder.layer.5.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.self.value.weight', 'bert_model.encoder.layer.1.attention.self.value.weight', 'bert_model.encoder.layer.10.attention.self.key.weight', 'bert_model.encoder.layer.6.output.dense.bias', 'bert_model.encoder.layer.3.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.self.value.bias', 'bert_model.encoder.layer.10.intermediate.dense.bias', 'bert_model.encoder.layer.3.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.11.attention.output.dense.weight', 'bert_model.encoder.layer.5.output.LayerNorm.bias', 'bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.output.dense.bias', 'bert_model.encoder.layer.9.attention.self.key.bias', 'bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.8.attention.self.key.bias', 'bert_model.encoder.layer.7.attention.self.key.weight', 'bert_model.encoder.layer.7.attention.self.value.weight', 'bert_model.encoder.layer.10.attention.output.dense.weight', 'bert_model.embeddings.position_embeddings.weight', 'bert_model.encoder.layer.2.output.dense.weight', 'bert_model.encoder.layer.1.intermediate.dense.bias', 'bert_model.encoder.layer.5.attention.self.value.bias', 'bert_model.encoder.layer.7.attention.self.query.weight', 'bert_model.encoder.layer.8.output.LayerNorm.bias', 'bert_model.encoder.layer.11.attention.self.query.bias', 'bert_model.encoder.layer.6.attention.output.dense.weight', 'bert_model.encoder.layer.9.output.LayerNorm.weight', 'bert_model.encoder.layer.4.intermediate.dense.bias', 'bert_model.encoder.layer.7.output.dense.weight', 'bert_model.encoder.layer.3.output.LayerNorm.bias', 'bert_model.encoder.layer.2.attention.self.query.bias', 'bert_model.encoder.layer.3.attention.self.key.bias', 'bert_model.encoder.layer.5.attention.self.key.weight', 'bert_model.encoder.layer.0.attention.output.dense.weight', 'bert_model.encoder.layer.2.attention.self.value.weight', 'bert_model.encoder.layer.11.intermediate.dense.bias', 'bert_model.encoder.layer.5.output.dense.bias', 'bert_model.encoder.layer.1.attention.output.dense.weight', 'bert_model.encoder.layer.4.output.LayerNorm.weight', 'bert_model.encoder.layer.8.attention.self.key.weight', 'bert_model.encoder.layer.8.attention.self.value.bias', 'bert_model.encoder.layer.9.attention.self.value.weight', 'bert_model.encoder.layer.11.attention.output.dense.bias', 'bert_model.encoder.layer.5.attention.self.query.bias', 'bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.9.attention.self.query.bias', 'bert_model.encoder.layer.6.attention.output.dense.bias', 'bert_model.encoder.layer.10.attention.self.key.bias', 'bert_model.encoder.layer.10.output.dense.weight', 'bert_model.encoder.layer.8.attention.self.query.bias', 'bert_model.encoder.layer.7.attention.self.value.bias', 'bert_model.encoder.layer.5.intermediate.dense.bias', 'bert_model.encoder.layer.4.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.1.attention.self.query.bias', 'bert_model.encoder.layer.0.attention.self.query.bias', 'bert_model.encoder.layer.0.output.dense.bias', 'bert_model.encoder.layer.9.output.dense.weight', 'bert_model.encoder.layer.4.attention.self.query.weight', 'bert_model.encoder.layer.6.attention.self.query.bias', 'bert_model.encoder.layer.4.attention.self.query.bias', 'bert_model.encoder.layer.5.attention.output.dense.bias', 'bert_model.encoder.layer.11.output.LayerNorm.weight', 'bert_model.encoder.layer.9.output.dense.bias', 'bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.9.output.LayerNorm.bias', 'bert_model.encoder.layer.10.output.LayerNorm.bias', 'bert_model.encoder.layer.9.attention.self.query.weight', 'bert_model.encoder.layer.1.attention.self.value.bias', 'bert_model.encoder.layer.6.attention.self.value.bias', 'bert_model.encoder.layer.7.attention.output.dense.weight', 'bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.1.attention.self.key.bias', 'bert_model.encoder.layer.8.attention.self.query.weight', 'bert_model.encoder.layer.2.intermediate.dense.bias', 'bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.0.attention.self.query.weight', 'bert_model.encoder.layer.6.intermediate.dense.weight', 'bert_model.encoder.layer.2.attention.self.query.weight', 'bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.10.output.dense.bias', 'bert_model.encoder.layer.10.output.LayerNorm.weight', 'bert_model.encoder.layer.0.intermediate.dense.weight', 'bert_model.encoder.layer.6.output.dense.weight', 'bert_model.encoder.layer.2.output.LayerNorm.bias', 'bert_model.encoder.layer.8.intermediate.dense.bias', 'bert_model.encoder.layer.4.attention.self.key.bias', 'bert_model.encoder.layer.7.attention.output.dense.bias', 'bert_model.encoder.layer.1.output.LayerNorm.bias', 'bert_model.encoder.layer.5.output.dense.weight', 'bert_model.encoder.layer.6.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.self.value.weight', 'bert_model.encoder.layer.1.output.dense.weight', 'bert_model.encoder.layer.0.attention.output.dense.bias', 'bert_model.encoder.layer.6.attention.self.query.weight', 'bert_model.embeddings.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.self.query.weight', 'bert_model.encoder.layer.8.intermediate.dense.weight', 'bert_model.encoder.layer.9.attention.output.dense.weight', 'bert_model.encoder.layer.6.attention.self.key.bias', 'bert_model.encoder.layer.7.intermediate.dense.bias', 'bert_model.encoder.layer.5.attention.self.key.bias', 'bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.11.output.dense.weight', 'bert_model.encoder.layer.5.attention.self.value.weight', 'bert_model.encoder.layer.6.attention.self.key.weight', 'bert_model.encoder.layer.1.attention.self.query.weight', 'bert_model.encoder.layer.4.attention.self.key.weight', 'bert_model.encoder.layer.3.attention.self.query.bias', 'bert_model.encoder.layer.2.attention.output.dense.bias', 'bert_model.encoder.layer.4.intermediate.dense.weight', 'bert_model.encoder.layer.10.attention.self.query.bias', 'bert_model.encoder.layer.1.attention.output.dense.bias', 'bert_model.encoder.layer.5.attention.self.query.weight', 'bert_model.encoder.layer.11.attention.self.key.bias', 'bert_model.encoder.layer.9.attention.output.dense.bias', 'bert_model.encoder.layer.2.attention.output.dense.weight', 'bert_model.encoder.layer.1.output.LayerNorm.weight', 'bert_model.encoder.layer.0.attention.self.value.weight', 'bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.4.attention.self.value.weight', 'bert_model.encoder.layer.7.attention.self.query.bias', 'bert_model.encoder.layer.0.attention.self.key.weight', 'bert_model.encoder.layer.0.intermediate.dense.bias', 'bert_model.pooler.dense.weight', 'bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.0.output.LayerNorm.weight', 'bert_model.encoder.layer.8.output.dense.bias', 'bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.5.attention.output.dense.weight', 'bert_model.pooler.dense.bias', 'bert_model.embeddings.word_embeddings.weight', 'bert_model.encoder.layer.7.intermediate.dense.weight', 'bert_model.encoder.layer.8.attention.output.dense.weight', 'bert_model.encoder.layer.4.output.LayerNorm.bias', 'bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.10.attention.output.dense.bias', 'bert_model.encoder.layer.3.attention.output.dense.weight', 'bert_model.embeddings.LayerNorm.bias', 'bert_model.encoder.layer.3.attention.output.dense.bias', 'bert_model.encoder.layer.0.output.LayerNorm.bias', 'bert_model.encoder.layer.9.intermediate.dense.bias', 'bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.self.query.weight', 'bert_model.encoder.layer.4.output.dense.weight', 'bert_model.encoder.layer.3.attention.self.key.weight', 'bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.self.key.weight', 'bert_model.encoder.layer.8.attention.output.dense.bias', 'bert_model.encoder.layer.4.output.dense.bias', 'bert_model.embeddings.token_type_embeddings.weight', 'bert_model.encoder.layer.9.intermediate.dense.weight', 'bert_model.encoder.layer.1.output.dense.bias', 'bert_model.encoder.layer.2.attention.self.value.bias', 'bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.1.intermediate.dense.weight', 'bert_model.encoder.layer.2.attention.self.key.bias', 'bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.2.attention.self.key.weight', 'bert_model.encoder.layer.2.output.dense.bias', 'bert_model.encoder.layer.11.attention.self.value.weight', 'bert_model.encoder.layer.3.intermediate.dense.bias', 'bert_model.encoder.layer.6.attention.self.value.weight', 'bert_model.encoder.layer.9.attention.self.key.weight', 'bert_model.encoder.layer.8.output.dense.weight', 'bert_model.encoder.layer.6.intermediate.dense.bias', 'bert_model.encoder.layer.9.attention.self.value.bias', 'bert_model.encoder.layer.11.output.LayerNorm.bias', 'bert_model.encoder.layer.4.attention.output.dense.bias', 'bert_model.encoder.layer.6.output.LayerNorm.bias', 'bert_model.encoder.layer.1.attention.self.key.weight', 'bert_model.encoder.layer.7.output.LayerNorm.weight', 'bert_model.encoder.layer.10.intermediate.dense.weight', 'bert_model.encoder.layer.11.output.dense.bias', 'bert_model.encoder.layer.2.intermediate.dense.weight', 'bert_model.encoder.layer.0.output.dense.weight', 'bert_model.encoder.layer.3.intermediate.dense.weight', 'bert_model.encoder.layer.11.attention.self.value.bias', 'bert_model.encoder.layer.4.attention.output.dense.weight', 'bert_model.encoder.layer.10.attention.self.query.weight', 'bert_model.encoder.layer.0.attention.self.key.bias', 'bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.3.output.dense.bias', 'bert_model.encoder.layer.5.intermediate.dense.weight', 'bert_model.encoder.layer.7.attention.self.key.bias', 'bert_model.encoder.layer.3.output.dense.weight', 'bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.2.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE dpr due to expand(torch.LongTensor{[2, 7, 1]}, size=[2, 768]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3) and WordPiece error: Missing [UNK] token from the vocabulary and expand(torch.LongTensor{[2, 7, 1]}, size=[2, 768]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)\n",
            "RUNNING:  xlm-prophetnet XLMProphetNetModel\n",
            "EXCEPTING once due to This model does not support the setting of `num_hidden_layers`. Please set `num_encoder_layers` and `num_decoder_layers`.\n",
            "rm: cannot remove './model/vocab.json': No such file or directory\n",
            "rm: cannot remove './model/merges.txt': No such file or directory\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n",
            "EXCEPTING twice due to Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260464318480 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260464318480 acquired on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "639a166b9d8b4c509107d92df3c0592d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260464318480 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260464318480 released on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260458827856 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/README.md.lock\n",
            "DEBUG:filelock:Lock 140260458827856 acquired on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "398fd25d00ed48049f3f7c6da6a8088b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260458827856 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/README.md.lock\n",
            "DEBUG:filelock:Lock 140260458827856 released on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260457004496 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260457004496 acquired on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fc3609eaa2a418f944ae5711f71f6a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260457004496 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260457004496 released on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260457004496 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/prophetnet.tokenizer.lock\n",
            "DEBUG:filelock:Lock 140260457004496 acquired on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/prophetnet.tokenizer.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86c2fb2093784cb0923ac0dbe0f1acc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260457004496 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/prophetnet.tokenizer.lock\n",
            "DEBUG:filelock:Lock 140260457004496 released on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/prophetnet.tokenizer.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260464318480 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260464318480 acquired on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d42dba8428ce4e6f901f0a1c64ce1f3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260464318480 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260464318480 released on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260477559440 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260477559440 acquired on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c606b38aff67451aac9e6863d470dfca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/134 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260477559440 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260477559440 released on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260464318480 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260464318480 acquired on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd6c15253b064782bbf27d617bf331fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260464318480 on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260464318480 released on /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased/tokenizer_config.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased. Creating a new one with MEAN pooling.\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/microsoft_xprophetnet-large-wiki100-cased were not used when initializing XLMProphetNetModel: ['lm_head.weight']\n",
            "- This IS expected if you are initializing XLMProphetNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMProphetNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE xlm-prophetnet due to This model does not support the setting of `num_hidden_layers`. Please set `num_encoder_layers` and `num_decoder_layers`. and Internal: src/sentencepiece_processor.cc(890) [model_proto->ParseFromArray(serialized.data(), serialized.size())]  and Either `decoder_input_ids` or `decoder_inputs_embeds` has to be passed.\n",
            "RUNNING:  prophetnet ProphetNetModel\n",
            "EXCEPTING once due to This model does not support the setting of `num_hidden_layers`. Please set `num_encoder_layers` and `num_decoder_layers`.\n",
            "rm: cannot remove './model/tokenizer_config.json': No such file or directory\n",
            "rm: cannot remove './model/special_tokens_map.json': No such file or directory\n",
            "rm: cannot remove './model/vocab.json': No such file or directory\n",
            "rm: cannot remove './model/merges.txt': No such file or directory\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/prophetnet.tokenizer: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to type of None unknown: <class 'NoneType'>. Should be one of a python, numpy, pytorch or tensorflow object.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260408775376 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260408775376 acquired on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f6532b7990149048d34221424323817",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260408775376 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260408775376 released on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452158160 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/README.md.lock\n",
            "DEBUG:filelock:Lock 140260452158160 acquired on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "953b4881e6594a76afcff8f6b3a8608b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452158160 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/README.md.lock\n",
            "DEBUG:filelock:Lock 140260452158160 released on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452223312 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260452223312 acquired on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57fd70739669474fa9077cef626afdc1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452223312 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/config.json.lock\n",
            "DEBUG:filelock:Lock 140260452223312 released on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260460570960 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/prophetnet.tokenizer.lock\n",
            "DEBUG:filelock:Lock 140260460570960 acquired on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/prophetnet.tokenizer.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b5685d1ce5a431391e12289becb50fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260460570960 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/prophetnet.tokenizer.lock\n",
            "DEBUG:filelock:Lock 140260460570960 released on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/prophetnet.tokenizer.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260451467536 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260451467536 acquired on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be8766a83f064da987696fe23821b3de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.57G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260451467536 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260451467536 released on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260452223312 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260452223312 acquired on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3fb33bb000c4d898c140fb0dc4b5995",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260452223312 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260452223312 released on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260451467536 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260451467536 acquired on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ce30a7a04194db0ac59b841169b61e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/141 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260451467536 on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260451467536 released on /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased/tokenizer_config.json.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased. Creating a new one with MEAN pooling.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/microsoft_prophetnet-large-uncased were not used when initializing ProphetNetModel: ['lm_head.weight']\n",
            "- This IS expected if you are initializing ProphetNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ProphetNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE prophetnet due to This model does not support the setting of `num_hidden_layers`. Please set `num_encoder_layers` and `num_decoder_layers`. and type of None unknown: <class 'NoneType'>. Should be one of a python, numpy, pytorch or tensorflow object. and forward() got an unexpected keyword argument 'token_type_ids'\n",
            "RUNNING:  mpnet MPNetModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for mpnet: (2, 768)\n",
            "RUNNING:  tapas TapasModel\n",
            "EXCEPTING once due to \n",
            "TapasModel requires the torch-scatter library but it was not found in your environment. You can install it with pip as\n",
            "explained here: https://github.com/rusty1s/pytorch_scatter.\n",
            "\n",
            "rm: cannot remove './model/tokenizer_config.json': No such file or directory\n",
            "rm: cannot remove './model/special_tokens_map.json': No such file or directory\n",
            "rm: cannot remove './model/vocab.json': No such file or directory\n",
            "rm: cannot remove './model/merges.txt': No such file or directory\n",
            "rm: cannot remove './model/added_tokens.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to ./model/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n",
            "file ./model/config.json not found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXCEPTING twice due to Can't load config for './model'. Make sure that:\n",
            "\n",
            "- './model' is a correct model identifier listed on 'https://huggingface.co/models'\n",
            "\n",
            "- or './model' is the correct path to a directory containing a config.json file\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140260472918480 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260472918480 acquired on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/.gitattributes.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5304335bf2a4da1beb30e72c79a5865",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260472918480 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/.gitattributes.lock\n",
            "DEBUG:filelock:Lock 140260472918480 released on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/.gitattributes.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260472918480 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/README.md.lock\n",
            "DEBUG:filelock:Lock 140260472918480 acquired on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/README.md.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab64f39b5ac347888c0e28cbcfc008d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/7.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260472918480 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/README.md.lock\n",
            "DEBUG:filelock:Lock 140260472918480 released on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/README.md.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260472918480 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/config.json.lock\n",
            "DEBUG:filelock:Lock 140260472918480 acquired on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d69225e63e14135b06f84542a3945a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260472918480 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/config.json.lock\n",
            "DEBUG:filelock:Lock 140260472918480 released on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260454181456 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260454181456 acquired on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/pytorch_model.bin.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bde614fb6fdd4e5f86b39cad33e30b27",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260454181456 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Lock 140260454181456 released on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/pytorch_model.bin.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260451325840 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260451325840 acquired on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/special_tokens_map.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "401d69b86cd649a890120f48ec987f42",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/154 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260451325840 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Lock 140260451325840 released on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/special_tokens_map.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260461445264 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260461445264 acquired on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/tokenizer_config.json.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "510944078eb541b4a1596814eb5bf172",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/490 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260461445264 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Lock 140260461445264 released on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/tokenizer_config.json.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 140260451325840 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260451325840 acquired on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/vocab.txt.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7186e863ed6741278ec185ae8f65ea99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/262k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140260451325840 on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/vocab.txt.lock\n",
            "DEBUG:filelock:Lock 140260451325840 released on /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa/vocab.txt.lock\n",
            "WARNING:root:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/google_tapas-base-finetuned-sqa. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCOMPATIBLE tapas due to \n",
            "TapasModel requires the torch-scatter library but it was not found in your environment. You can install it with pip as\n",
            "explained here: https://github.com/rusty1s/pytorch_scatter.\n",
            " and Can't load config for './model'. Make sure that:\n",
            "\n",
            "- './model' is a correct model identifier listed on 'https://huggingface.co/models'\n",
            "\n",
            "- or './model' is the correct path to a directory containing a config.json file\n",
            "\n",
            " and \n",
            "TapasModel requires the torch-scatter library but it was not found in your environment. You can install it with pip as\n",
            "explained here: https://github.com/rusty1s/pytorch_scatter.\n",
            "\n",
            "RUNNING:  ibert IBertModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for ibert: (2, 768)\n",
            "RUNNING:  splinter SplinterModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No sentence-transformers model found with name ./model. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output for splinter: (2, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyAZL2ct0CX9",
        "outputId": "28668de0-f5db-4fa3-d2cc-2a89fda897bc"
      },
      "source": [
        "SE_COMP_MAPPING"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('fnet', False),\n",
              "             ('gptj', False),\n",
              "             ('layoutlmv2', False),\n",
              "             ('beit', False),\n",
              "             ('rembert', True),\n",
              "             ('visual_bert', False),\n",
              "             ('canine', True),\n",
              "             ('roformer', True),\n",
              "             ('clip', False),\n",
              "             ('bigbird_pegasus', True),\n",
              "             ('deit', False),\n",
              "             ('luke', True),\n",
              "             ('detr', False),\n",
              "             ('gpt_neo', True),\n",
              "             ('big_bird', True),\n",
              "             ('speech_to_text', False),\n",
              "             ('vit', False),\n",
              "             ('wav2vec2', False),\n",
              "             ('hubert', False),\n",
              "             ('m2m_100', False),\n",
              "             ('convbert', True),\n",
              "             ('led', True),\n",
              "             ('blenderbot-small', False),\n",
              "             ('retribert', False),\n",
              "             ('mt5', False),\n",
              "             ('t5', False),\n",
              "             ('pegasus', False),\n",
              "             ('marian', False),\n",
              "             ('mbart', True),\n",
              "             ('distilbert', True),\n",
              "             ('albert', True),\n",
              "             ('camembert', True),\n",
              "             ('xlm-roberta', True),\n",
              "             ('bart', True),\n",
              "             ('longformer', True),\n",
              "             ('roberta', True),\n",
              "             ('layoutlm', True),\n",
              "             ('squeezebert', True),\n",
              "             ('bert', True),\n",
              "             ('openai-gpt', True),\n",
              "             ('gpt2', True),\n",
              "             ('megatron-bert', False),\n",
              "             ('mobilebert', True),\n",
              "             ('transfo-xl', False),\n",
              "             ('xlnet', False),\n",
              "             ('flaubert', True),\n",
              "             ('fsmt', True),\n",
              "             ('xlm', True),\n",
              "             ('ctrl', True),\n",
              "             ('electra', True),\n",
              "             ('reformer', False),\n",
              "             ('funnel', True),\n",
              "             ('lxmert', False),\n",
              "             ('bert-generation', True),\n",
              "             ('deberta', True),\n",
              "             ('deberta-v2', True),\n",
              "             ('dpr', False),\n",
              "             ('xlm-prophetnet', False),\n",
              "             ('prophetnet', False),\n",
              "             ('mpnet', True),\n",
              "             ('tapas', False),\n",
              "             ('ibert', True),\n",
              "             ('splinter', True)])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXmOEPKfu6F_",
        "outputId": "a57ff91c-7452-45b1-cb3e-542713a5ea16"
      },
      "source": [
        "for k, v in sorted(SE_COMP_MAPPING.items()):\n",
        "    if v:\n",
        "      print(f'\"{k}\",')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"albert\",\n",
            "\"bart\",\n",
            "\"bert\",\n",
            "\"bert-generation\",\n",
            "\"big_bird\",\n",
            "\"bigbird_pegasus\",\n",
            "\"camembert\",\n",
            "\"canine\",\n",
            "\"convbert\",\n",
            "\"ctrl\",\n",
            "\"deberta\",\n",
            "\"deberta-v2\",\n",
            "\"distilbert\",\n",
            "\"electra\",\n",
            "\"flaubert\",\n",
            "\"fsmt\",\n",
            "\"funnel\",\n",
            "\"gpt2\",\n",
            "\"gpt_neo\",\n",
            "\"ibert\",\n",
            "\"layoutlm\",\n",
            "\"led\",\n",
            "\"longformer\",\n",
            "\"luke\",\n",
            "\"mbart\",\n",
            "\"mobilebert\",\n",
            "\"mpnet\",\n",
            "\"openai-gpt\",\n",
            "\"rembert\",\n",
            "\"roberta\",\n",
            "\"roformer\",\n",
            "\"splinter\",\n",
            "\"squeezebert\",\n",
            "\"xlm\",\n",
            "\"xlm-roberta\",\n"
          ]
        }
      ]
    }
  ]
}